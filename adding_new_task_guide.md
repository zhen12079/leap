# LeapAIæ¡†æ¶æ·»åŠ æ–°æ„ŸçŸ¥ä»»åŠ¡æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨LeapAIæ¡†æ¶ä¸­æ·»åŠ ä¸€ä¸ªæ–°çš„æ„ŸçŸ¥ä»»åŠ¡ã€‚æˆ‘ä»¬å°†ä»¥æ·»åŠ ä¸€ä¸ª"äº¤é€šæ ‡å¿—æ£€æµ‹"ä»»åŠ¡ä¸ºä¾‹ï¼Œå±•ç¤ºå®Œæ•´çš„æ‰©å±•æµç¨‹ã€‚

## ğŸ“‹ ä»»åŠ¡åˆ†æ

### æ–°ä»»åŠ¡ï¼šäº¤é€šæ ‡å¿—æ£€æµ‹
- **ä»»åŠ¡ç±»å‹**: ç›®æ ‡æ£€æµ‹
- **è¾“å…¥**: BEVç‰¹å¾å›¾
- **è¾“å‡º**: äº¤é€šæ ‡å¿—çš„3Dè¾¹ç•Œæ¡†å’Œç±»åˆ«
- **ç±»åˆ«**: ç¦æ­¢æ ‡å¿—ã€è­¦å‘Šæ ‡å¿—ã€æŒ‡ç¤ºæ ‡å¿—ç­‰

## ğŸš€ å®ç°æ­¥éª¤

### æ­¥éª¤1ï¼šåˆ›å»ºä»»åŠ¡é…ç½®æ–‡ä»¶

#### 1.1 åˆ›å»ºé…ç½®æ–‡ä»¶
```python
# projects/perception/configs/traffic_sign.py
import os
from copy import deepcopy
from functools import partial

import numpy as np
import torch.nn as nn
from mmdet.models import losses

from projects.perception import base, model_base
from projects.perception.callback.metric.traffic_sign_metric import (
    TrafficSignMetric,
)
from projects.perception.dataset.frame_sampler import FrameSamplerTrafficSign
from projects.perception.dataset.gt_mask import GTMask
from projects.perception.model.head.traffic_sign_head import TrafficSignHead
from projects.perception.target.traffic_sign_target import TrafficSignTarget
from projects.perception.transforms.augment_transfer import GenerateAugMatrix

# åŸºç¡€é…ç½®
save_root = base.save_root
embed_dims = model_base.embed_dims
camera_names = model_base.camera_names
resize_hw = model_base.resize_hw
batch_size = model_base.batch_sizes.get("traffic_sign", 16)
num_workers = model_base.num_workers.get("traffic_sign", 4)
lidar_range = model_base.lidar_range.get("traffic_sign", [-50, -50, -3, 50, 50, 5])

# ä»»åŠ¡ç‰¹å®šé…ç½®
task_name = "traffic_sign"
anno_name = "annos_traffic_sign"
bev_h, bev_w = 128, 128  # BEVç‰¹å¾å›¾å°ºå¯¸

# ç±»åˆ«å®šä¹‰
class_names = [
    "prohibitory",      # ç¦æ­¢æ ‡å¿—
    "warning",         # è­¦å‘Šæ ‡å¿—  
    "mandatory",       # æŒ‡ç¤ºæ ‡å¿—
    "priority",        # ä¼˜å…ˆæƒæ ‡å¿—
    "information",    # ä¿¡æ¯æ ‡å¿—
]
num_classes = len(class_names)
category2id = {
    "prohibitory": 0,
    "warning": 1,
    "mandatory": 2,
    "priority": 3,
    "information": 4,
}

# æ£€æµ‹é…ç½®
max_objects = 100
post_center_range = [-50, -50, -5, 50, 50, 5]
```

#### 1.2 æ•°æ®å¤„ç†é…ç½®
```python
# æ•°æ®å¢å¼ºé…ç½®
augment_2d_flag = True
augment_3d_flag = True

if augment_2d_flag:
    data_config_2d = {
        "brightness": 0.2,
        "contrast": 0.2,
        "saturation": 0.2,
        "hue": 0.1,
        "resize": (-0.1, 0.1),
        "crop": (-0.05, 0.05),
        "rot": (-3.0, 3.0),
        "flip": True,
    }

if augment_3d_flag:
    data_config_3d = {
        "rotate_z": [1.0, (-10, 10)],
        "scale": (0.9, 1.1),
        "x_trans": (-2, 2),
        "y_trans": (-2, 2),
        "z_trans": (-1, 1),
    }

# è®­ç»ƒæ•°æ®ç®¡é“
train_pipeline = []
if augment_2d_flag or augment_3d_flag:
    train_pipeline.append(
        dict(
            type=GenerateAugMatrix,
            apply_names=camera_names,
            resize_hw=resize_hw,
            prob=0.5,
            data_aug_config_2d=data_config_2d if augment_2d_flag else None,
            data_aug_config_3d=data_config_3d if augment_3d_flag else None,
        )
    )

train_pipeline.append(
    dict(
        type=TrafficSignTarget,
        lidar_range=lidar_range,
        anno_name=anno_name,
        max_objects=max_objects,
        category2id=category2id,
        gt_augment_transform=True if augment_3d_flag else False,
    )
)

# éªŒè¯æ•°æ®ç®¡é“
val_pipeline = [
    dict(
        type=TrafficSignTarget,
        lidar_range=lidar_range,
        anno_name=anno_name,
        max_objects=max_objects,
        category2id=category2id,
        gt_augment_transform=False,
    )
]
```

#### 1.3 æ•°æ®é›†é…ç½®
```python
# å¸§é‡‡æ ·å™¨
def get_frame_sampler(down_sample_ratio):
    frame_sampler = dict(
        type=FrameSamplerTrafficSign,
        need_continuous=False,  # äº¤é€šæ ‡å¿—é€šå¸¸ä¸éœ€è¦æ—¶åºä¿¡æ¯
        label_sample_scene={
            "intersection": 0.8,  # é‡ç‚¹é‡‡æ ·è·¯å£åœºæ™¯
            "highway": 0.6,
            "urban": 0.4,
        },
        need_fix_sample=True if down_sample_ratio > 1 else False,
    )
    return frame_sampler

# æ•°æ®é›†é…ç½®
train_sample_config = dict(
    crop_frame_num=1,
    enable_temporal_sample=False,
)

val_sample_config = dict(
    sample_interval=1,
)

# æ•°æ®é›†è·å–å‡½æ•°
get_train_dataset = partial(
    model_base.get_dataset,
    pipeline=train_pipeline,
    frame_sampler=get_frame_sampler(1),
    sample_config=train_sample_config,
    length_for_rank_split=1000,
)

get_val_dataset = partial(
    model_base.get_test_dataset,
    pipeline=val_pipeline,
    frame_sampler=get_frame_sampler(1),
    sample_config=val_sample_config,
)
```

### æ­¥éª¤2ï¼šåˆ›å»ºç›®æ ‡å¤„ç†æ¨¡å—

#### 2.1 åˆ›å»ºç›®æ ‡å¤„ç†ç±»
```python
# projects/perception/target/traffic_sign_target.py
import numpy as np
import torch
from mmdet.core.bbox import BaseBox3D

class TrafficSignTarget:
    def __init__(self, lidar_range, anno_name, max_objects, category2id, gt_augment_transform=False):
        self.lidar_range = lidar_range
        self.anno_name = anno_name
        self.max_objects = max_objects
        self.category2id = category2id
        self.gt_augment_transform = gt_augment_transform
        
    def __call__(self, results):
        """å¤„ç†äº¤é€šæ ‡å¿—æ ‡æ³¨æ•°æ®"""
        # è·å–æ ‡æ³¨ä¿¡æ¯
        annos = results.get(self.anno_name, {})
        
        if not annos:
            # å¦‚æœæ²¡æœ‰æ ‡æ³¨ï¼Œè¿”å›ç©ºçš„ç›®æ ‡
            return self._get_empty_targets(results)
        
        # æå–3Dè¾¹ç•Œæ¡†ä¿¡æ¯
        gt_boxes_3d = []
        gt_labels = []
        gt_masks = []
        
        for anno in annos:
            if 'bbox_3d' in anno:
                bbox_3d = anno['bbox_3d']
                category = anno.get('category', 'unknown')
                
                if category in self.category2id:
                    # è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
                    gt_box = self._convert_bbox(bbox_3d)
                    gt_label = self.category2id[category]
                    
                    gt_boxes_3d.append(gt_box)
                    gt_labels.append(gt_label)
                    gt_masks.append(1.0)
        
        # è½¬æ¢ä¸ºtensor
        if gt_boxes_3d:
            gt_boxes_3d = torch.tensor(gt_boxes_3d, dtype=torch.float32)
            gt_labels = torch.tensor(gt_labels, dtype=torch.long)
            gt_masks = torch.tensor(gt_masks, dtype=torch.float32)
        else:
            gt_boxes_3d = torch.zeros((0, 7), dtype=torch.float32)  # x,y,z,w,l,h,theta
            gt_labels = torch.zeros((0,), dtype=torch.long)
            gt_masks = torch.zeros((0,), dtype=torch.float32)
        
        # å¡«å……åˆ°æœ€å¤§æ•°é‡
        if len(gt_boxes_3d) < self.max_objects:
            pad_size = self.max_objects - len(gt_boxes_3d)
            gt_boxes_3d = torch.cat([
                gt_boxes_3d,
                torch.zeros((pad_size, 7), dtype=torch.float32)
            ], dim=0)
            gt_labels = torch.cat([
                gt_labels,
                torch.zeros((pad_size,), dtype=torch.long)
            ], dim=0)
            gt_masks = torch.cat([
                gt_masks,
                torch.zeros((pad_size,), dtype=torch.float32)
            ], dim=0)
        
        # æ›´æ–°ç»“æœ
        results[f'{self.anno_name}_gt_boxes'] = gt_boxes_3d
        results[f'{self.anno_name}_gt_labels'] = gt_labels
        results[f'{self.anno_name}_gt_masks'] = gt_masks
        
        return results
    
    def _convert_bbox(self, bbox_3d):
        """è½¬æ¢3Dè¾¹ç•Œæ¡†æ ¼å¼"""
        # å‡è®¾è¾“å…¥æ ¼å¼ä¸º: [x, y, z, dx, dy, dz, heading]
        # è¾“å‡ºæ ¼å¼ä¸º: [x, y, z, w, l, h, theta]
        x, y, z, dx, dy, dz, heading = bbox_3d
        return [x, y, z, dy, dx, dz, heading]  # w=dy, l=dx, h=dz
    
    def _get_empty_targets(self, results):
        """è¿”å›ç©ºçš„ç›®æ ‡"""
        gt_boxes_3d = torch.zeros((self.max_objects, 7), dtype=torch.float32)
        gt_labels = torch.zeros((self.max_objects,), dtype=torch.long)
        gt_masks = torch.zeros((self.max_objects,), dtype=torch.float32)
        
        results[f'{self.anno_name}_gt_boxes'] = gt_boxes_3d
        results[f'{self.anno_name}_gt_labels'] = gt_labels
        results[f'{self.anno_name}_gt_masks'] = gt_masks
        
        return results
```

### æ­¥éª¤3ï¼šåˆ›å»ºæ¨¡å‹å¤´éƒ¨

#### 3.1 åˆ›å»ºæ£€æµ‹å¤´
```python
# projects/perception/model/head/traffic_sign_head.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from mmdet.models import losses

class TrafficSignHead(nn.Module):
    def __init__(self, 
                 bev_h, bev_w, 
                 num_classes, num_query,
                 embed_dims, 
                 in_channels,
                 code_size=7,
                 use_aux_loss=True):
        super().__init__()
        
        self.bev_h = bev_h
        self.bev_w = bev_w
        self.num_classes = num_classes
        self.num_query = num_query
        self.embed_dims = embed_dims
        self.code_size = code_size
        self.use_aux_loss = use_aux_loss
        
        # æŸ¥è¯¢åµŒå…¥
        self.query_embedding = nn.Embedding(num_query, embed_dims)
        
        # Transformerè§£ç å™¨
        self.decoder = self._build_decoder()
        
        # åˆ†ç±»å¤´
        self.class_head = nn.Linear(embed_dims, num_classes)
        
        # å›å½’å¤´
        self.bbox_head = nn.Linear(embed_dims, code_size)
        
        # è¾…åŠ©åˆ†ç±»å¤´
        if use_aux_loss:
            self.aux_class_head = nn.Linear(embed_dims, num_classes)
        
        # æŸå¤±å‡½æ•°
        self.loss_cls = losses.FocalLoss(
            use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0
        )
        self.loss_bbox = losses.L1Loss(loss_weight=0.25)
        
    def _build_decoder(self):
        """æ„å»ºTransformerè§£ç å™¨"""
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=self.embed_dims,
            nhead=8,
            dim_feedforward=self.embed_dims * 4,
            dropout=0.1,
            activation='relu',
            batch_first=True
        )
        return nn.TransformerDecoder(
            decoder_layer, num_layers=6
        )
    
    def forward(self, bev_features, metas=None):
        """å‰å‘ä¼ æ’­"""
        batch_size = bev_features.size(0)
        
        # å±•å¹³BEVç‰¹å¾
        bev_flat = bev_features.flatten(2).permute(0, 2, 1)  # [B, H*W, C]
        
        # ç”ŸæˆæŸ¥è¯¢
        query = self.query_embedding.weight.unsqueeze(0).repeat(batch_size, 1, 1)
        
        # Transformerè§£ç 
        output = self.decoder(
            query.transpose(0, 1),  # [num_query, B, C]
            bev_flat.transpose(0, 1)  # [H*W, B, C]
        ).transpose(0, 1)  # [B, num_query, C]
        
        # åˆ†ç±»å’Œå›å½’
        cls_logits = self.class_head(output)  # [B, num_query, num_classes]
        bbox_pred = self.bbox_head(output)   # [B, num_query, code_size]
        
        # è¾…åŠ©åˆ†ç±»
        if self.use_aux_loss:
            aux_cls_logits = self.aux_class_head(output)
        else:
            aux_cls_logits = None
        
        return {
            'cls_logits': cls_logits,
            'bbox_pred': bbox_pred,
            'aux_cls_logits': aux_cls_logits,
            'query': query,
        }
    
    def loss(self, gt_boxes, gt_labels, gt_masks, predictions):
        """è®¡ç®—æŸå¤±"""
        cls_logits = predictions['cls_logits']
        bbox_pred = predictions['bbox_pred']
        aux_cls_logits = predictions.get('aux_cls_logits')
        
        # è®¡ç®—åˆ†ç±»æŸå¤±
        loss_cls = self.loss_cls(cls_logits, gt_labels, gt_masks)
        
        # è®¡ç®—å›å½’æŸå¤±ï¼ˆåªå¯¹æ­£æ ·æœ¬è®¡ç®—ï¼‰
        pos_mask = gt_masks > 0
        if pos_mask.sum() > 0:
            pos_bbox_pred = bbox_pred[pos_mask]
            pos_gt_boxes = gt_boxes[pos_mask]
            loss_bbox = self.loss_bbox(pos_bbox_pred, pos_gt_boxes)
        else:
            loss_bbox = bbox_pred.sum() * 0
        
        # è¾…åŠ©åˆ†ç±»æŸå¤±
        loss_aux = 0
        if aux_cls_logits is not None:
            loss_aux = self.loss_cls(aux_cls_logits, gt_labels, gt_masks)
        
        return {
            'loss_cls': loss_cls,
            'loss_bbox': loss_bbox,
            'loss_aux': loss_aux,
        }
    
    def get_results(self, predictions, metas=None):
        """è·å–æ¨ç†ç»“æœ"""
        cls_logits = predictions['cls_logits']
        bbox_pred = predictions['bbox_pred']
        
        # åº”ç”¨sigmoidå’Œsoftmax
        cls_scores = torch.sigmoid(cls_logits)
        
        # åå¤„ç†ï¼ˆNMSç­‰ï¼‰
        results = []
        batch_size = cls_scores.size(0)
        
        for i in range(batch_size):
            # è·å–å½“å‰æ‰¹æ¬¡çš„ç»“æœ
            batch_cls_scores = cls_scores[i]  # [num_query, num_classes]
            batch_bbox_pred = bbox_pred[i]   # [num_query, code_size]
            
            # è·å–æœ€å¤§åˆ†æ•°å’Œå¯¹åº”ç±»åˆ«
            max_scores, max_classes = torch.max(batch_cls_scores, dim=-1)
            
            # ç®€å•çš„é˜ˆå€¼è¿‡æ»¤
            score_threshold = 0.3
            valid_mask = max_scores > score_threshold
            
            if valid_mask.sum() > 0:
                valid_boxes = batch_bbox_pred[valid_mask]
                valid_scores = max_scores[valid_mask]
                valid_classes = max_classes[valid_mask]
                
                results.append({
                    'boxes_3d': valid_boxes.cpu().numpy(),
                    'scores': valid_scores.cpu().numpy(),
                    'labels': valid_classes.cpu().numpy(),
                })
            else:
                results.append({
                    'boxes_3d': np.zeros((0, 7)),
                    'scores': np.zeros((0,)),
                    'labels': np.zeros((0,), dtype=np.int64),
                })
        
        return {
            'traffic_sign_results': results
        }
```

### æ­¥éª¤4ï¼šåˆ›å»ºæ•°æ®é‡‡æ ·å™¨

#### 4.1 åˆ›å»ºå¸§é‡‡æ ·å™¨
```python
# projects/perception/dataset/frame_sampler.py
class FrameSamplerTrafficSign:
    def __init__(self, 
                 need_continuous=False,
                 label_sample_scene=None,
                 need_fix_sample=False):
        self.need_continuous = need_continuous
        self.label_sample_scene = label_sample_scene or {}
        self.need_fix_sample = need_fix_sample
        
    def __call__(self, frame_infos, sample_config):
        """é‡‡æ ·äº¤é€šæ ‡å¿—ç›¸å…³çš„å¸§"""
        if not self.need_continuous:
            # ä¸éœ€è¦è¿ç»­å¸§ï¼Œéšæœºé‡‡æ ·
            if len(frame_infos) > 0:
                return [np.random.choice(frame_infos)]
            else:
                return []
        
        # éœ€è¦è¿ç»­å¸§çš„é‡‡æ ·é€»è¾‘
        sampled_frames = []
        # å®ç°å…·ä½“çš„é‡‡æ ·é€»è¾‘
        return sampled_frames
```

### æ­¥éª¤5ï¼šåˆ›å»ºè¯„ä¼°æŒ‡æ ‡

#### 5.1 åˆ›å»ºè¯„ä¼°æŒ‡æ ‡ç±»
```python
# projects/perception/callback/metric/traffic_sign_metric.py
import numpy as np
from leapai.callback.metric.base_metric import BaseMetric

class TrafficSignMetric(BaseMetric):
    def __init__(self, 
                 task_name,
                 annotation_name,
                 save_dir,
                 class_names,
                 distance_threshold=2.0,
                 score_threshold=0.3):
        super().__init__()
        self.task_name = task_name
        self.annotation_name = annotation_name
        self.save_dir = save_dir
        self.class_names = class_names
        self.distance_threshold = distance_threshold
        self.score_threshold = score_threshold
        
        self.reset()
    
    def reset(self):
        """é‡ç½®æŒ‡æ ‡"""
        self.predictions = []
        self.ground_truths = []
    
    def process(self, predictions, ground_truth):
        """å¤„ç†å•ä¸ªæ ·æœ¬çš„é¢„æµ‹å’ŒçœŸå€¼"""
        self.predictions.extend(predictions)
        self.ground_truths.extend(ground_truth)
    
    def compute_metrics(self):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        # è®¡ç®—mAPã€ç²¾ç¡®ç‡ã€å¬å›ç‡ç­‰
        ap_per_class = []
        
        for class_id, class_name in enumerate(self.class_names):
            ap = self._compute_ap_for_class(class_id)
            ap_per_class.append(ap)
            print(f"{class_name} AP: {ap:.4f}")
        
        # è®¡ç®—å¹³å‡AP
        map_score = np.mean(ap_per_class)
        print(f"mAP: {map_score:.4f}")
        
        return {
            'mAP': map_score,
            'AP_per_class': dict(zip(self.class_names, ap_per_class))
        }
    
    def _compute_ap_for_class(self, class_id):
        """è®¡ç®—å•ä¸ªç±»åˆ«çš„AP"""
        # å®ç°APè®¡ç®—é€»è¾‘
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦å®Œæ•´çš„IoUè®¡ç®—å’ŒAPè®¡ç®—
        return 0.0  # å ä½ç¬¦
    
    def save_results(self, results):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        import json
        import os
        
        save_path = os.path.join(self.save_dir, f"{self.task_name}_results.json")
        with open(save_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
```

### æ­¥éª¤6ï¼šåˆ›å»ºæ‹“æ‰‘å‡½æ•°

#### 6.1 åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ æ‹“æ‰‘
```python
# åœ¨ traffic_sign.py ä¸­æ·»åŠ 
# ----------------------------------Nodes-------------------------------------
nodes = {}

# BEV Neck
traffic_sign_neck = dict(
    type=Conv3x3Neck,
    input_c=embed_dims * 2,
    output_c=embed_dims,
)
neck_name = f"{task_name}_neck"
nodes[neck_name] = traffic_sign_neck

# æ£€æµ‹å¤´
traffic_sign_head = dict(
    type=TrafficSignHead,
    bev_h=bev_h,
    bev_w=bev_w,
    num_classes=num_classes,
    num_query=256,
    embed_dims=embed_dims,
    in_channels=embed_dims,
    code_size=7,
    use_aux_loss=True,
)
head_name = f"{task_name}_head"
nodes[head_name] = traffic_sign_head

# ------------------------------topology--------------------------------------
def node_topology(state, model, batch, bev_feats, metas):
    """äº¤é€šæ ‡å¿—æ£€æµ‹æ‹“æ‰‘"""
    bev_neck = getattr(model, neck_name)
    bev_feats = bev_neck(bev_feats)
    
    head = getattr(model, head_name)
    head_pred = head(bev_feats, metas)
    
    if state == "train":
        gt = batch[anno_name]
        losses = head.loss(
            gt[f'{anno_name}_gt_boxes'],
            gt[f'{anno_name}_gt_labels'],
            gt[f'{anno_name}_gt_masks'],
            head_pred
        )
        return losses
    elif state == "val":
        preds = head.get_results(head_pred, metas)
        return preds
    else:
        raise NotImplementedError(state)

# ------------------------------metric-------------------------------------
def get_metric(test_set_name):
    """è·å–è¯„ä¼°æŒ‡æ ‡"""
    traffic_sign_metric = dict(
        type=TrafficSignMetric,
        task_name=test_set_name,
        annotation_name=anno_name,
        save_dir=save_root,
        class_names=class_names,
        distance_threshold=2.0,
        score_threshold=0.3,
    )
    return traffic_sign_metric
```

### æ­¥éª¤7ï¼šé›†æˆåˆ°ä¸»é…ç½®

#### 7.1 ä¿®æ”¹ä¸»é…ç½®æ–‡ä»¶
```python
# åœ¨ä¸»é…ç½®æ–‡ä»¶ä¸­æ·»åŠ äº¤é€šæ ‡å¿—ä»»åŠ¡
# ä¾‹å¦‚åœ¨ lpperception_current_hpa_step1.py ä¸­æ·»åŠ ï¼š

# å¯ç”¨äº¤é€šæ ‡å¿—ä»»åŠ¡
traffic_sign_task = True

# æ›´æ–°å¤šä»»åŠ¡é…ç½®
multi_task_config = MAIN_CFG.multi_task_config.copy()
if traffic_sign_task:
    multi_task_config["traffic_sign"] = "projects/perception/traffic_sign.py"

# æ›´æ–°æ•°æ®é›†é…ç½®
if traffic_sign_task:
    train_set_info_path["traffic_sign"] = {
        "online": [
            "/path/to/traffic_sign_train_list.txt",
        ],
        "offline": "",
        "lmdb_path": "/path/to/traffic_sign_lmdb.txt",
    }
    
    val_set_info_path["traffic_sign"] = {
        "traffic_sign_test": dict(
            path="/path/to/traffic_sign_test_list.txt",
            lmdb_path="/path/to/traffic_sign_lmdb.txt",
        ),
    }

# æ›´æ–°æ‰¹æ¬¡å¤§å°å’Œé‡‡æ ·é…ç½®
batch_sizes["traffic_sign"] = {"train": 8, "val": 1}
num_workers["traffic_sign"] = {"train": 4, "val": 4}
use_rank_split["traffic_sign"] = True
down_sample_ratio["traffic_sign"] = {"train": 1, "val": 1}
max_samples["traffic_sign"] = 100
```

### æ­¥éª¤8ï¼šåˆ›å»ºå¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶

#### 8.1 åˆ›å»ºç›®å½•ç»“æ„
```bash
# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p projects/perception/model/head
mkdir -p projects/perception/target
mkdir -p projects/perception/callback/metric
mkdir -p projects/perception/dataset
```

#### 8.2 åˆ›å»º__init__.pyæ–‡ä»¶
```python
# projects/perception/model/head/__init__.py
from .traffic_sign_head import TrafficSignHead

__all__ = ['TrafficSignHead']

# projects/perception/target/__init__.py
from .traffic_sign_target import TrafficSignTarget

__all__ = ['TrafficSignTarget']

# projects/perception/callback/metric/__init__.py
from .traffic_sign_metric import TrafficSignMetric

__all__ = ['TrafficSignMetric']
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### æµ‹è¯•é…ç½®åŠ è½½
```python
def test_traffic_sign_config():
    """æµ‹è¯•äº¤é€šæ ‡å¿—é…ç½®åŠ è½½"""
    import sys
    sys.path.append('/dahuafs/userdata/40359/Leapnet_master')
    
    from projects.perception.configs.traffic_sign import (
        class_names, category2id, get_train_dataset, 
        get_val_dataset, nodes, node_topology, get_metric
    )
    
    print("=== äº¤é€šæ ‡å¿—ä»»åŠ¡é…ç½®æµ‹è¯• ===")
    print(f"ç±»åˆ«æ•°é‡: {len(class_names)}")
    print(f"ç±»åˆ«: {class_names}")
    print(f"èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
    print("é…ç½®åŠ è½½æˆåŠŸ!")

test_traffic_sign_config()
```

### æµ‹è¯•æ•°æ®æµ
```python
def test_data_flow():
    """æµ‹è¯•æ•°æ®æµ"""
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size = 2
    bev_h, bev_w = 128, 128
    embed_dims = 256
    
    # æ¨¡æ‹ŸBEVç‰¹å¾
    bev_features = torch.randn(batch_size, embed_dims, bev_h, bev_w)
    
    # æ¨¡æ‹Ÿå…ƒæ•°æ®
    metas = [{"scene_id": f"scene_{i}"} for i in range(batch_size)]
    
    # æµ‹è¯•æ¨¡å‹å¤´éƒ¨
    from projects.perception.model.head.traffic_sign_head import TrafficSignHead
    
    head = TrafficSignHead(
        bev_h=bev_h, bev_w=bev_w,
        num_classes=5, num_query=256,
        embed_dims=embed_dims, in_channels=embed_dims
    )
    
    # å‰å‘ä¼ æ’­
    predictions = head(bev_features, metas)
    
    print("=== æ•°æ®æµæµ‹è¯• ===")
    print(f"BEVç‰¹å¾å½¢çŠ¶: {bev_features.shape}")
    print(f"åˆ†ç±»logitså½¢çŠ¶: {predictions['cls_logits'].shape}")
    print(f"è¾¹ç•Œæ¡†é¢„æµ‹å½¢çŠ¶: {predictions['bbox_pred'].shape}")
    print("æ•°æ®æµæµ‹è¯•æˆåŠŸ!")

test_data_flow()
```

## ğŸš€ éƒ¨ç½²å’Œä½¿ç”¨

### å¯åŠ¨è®­ç»ƒ
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export LEAPAI_TASK_CONFIG="projects/perception/configs/lpperception_with_traffic_sign.py"
export RCNUM=1
export GPU_NUM=1
export my_debug="yes"

# å¯åŠ¨è®­ç»ƒ
python -m projects.perception.entry
```

### ç›‘æ§è®­ç»ƒ
```python
# ç›‘æ§äº¤é€šæ ‡å¿—ä»»åŠ¡çš„è®­ç»ƒè¿›åº¦
def monitor_traffic_sign_training():
    """ç›‘æ§äº¤é€šæ ‡å¿—è®­ç»ƒ"""
    # å®ç°è®­ç»ƒç›‘æ§é€»è¾‘
    print("ç›‘æ§äº¤é€šæ ‡å¿—ä»»åŠ¡è®­ç»ƒ...")
    
monitor_traffic_sign_training()
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–
- ä½¿ç”¨LMDBåŠ é€Ÿæ•°æ®è¯»å–
- åˆç†è®¾ç½®num_workers
- å¯ç”¨æ•°æ®é¢„å–

### 2. æ¨¡å‹ä¼˜åŒ–
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- å®ç°æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–
- ä¼˜åŒ–Transformerç»“æ„

### 3. è®­ç»ƒç­–ç•¥
- ä½¿ç”¨å­¦ä¹ ç‡é¢„çƒ­
- å®ç°æ¢¯åº¦ç´¯ç§¯
- æ·»åŠ æ­£åˆ™åŒ–æŠ€æœ¯

## ğŸ”§ å¸¸è§é—®é¢˜è§£å†³

### 1. å¯¼å…¥é”™è¯¯
```python
# ç¡®ä¿æ‰€æœ‰æ¨¡å—æ­£ç¡®å¯¼å…¥
try:
    from projects.perception.configs.traffic_sign import *
    print("äº¤é€šæ ‡å¿—æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"å¯¼å…¥å¤±è´¥: {e}")
```

### 2. é…ç½®å†²çª
```python
# æ£€æŸ¥é…ç½®å…¼å®¹æ€§
def check_config_compatibility():
    """æ£€æŸ¥é…ç½®å…¼å®¹æ€§"""
    # å®ç°é…ç½®æ£€æŸ¥é€»è¾‘
    pass

check_config_compatibility()
```

### 3. å†…å­˜é—®é¢˜
```python
# ä¼˜åŒ–å†…å­˜ä½¿ç”¨
def optimize_memory():
    """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    torch.cuda.empty_cache()
    # å…¶ä»–å†…å­˜ä¼˜åŒ–ç­–ç•¥

optimize_memory()
```

## ğŸ¯ æ€»ç»“

é€šè¿‡æœ¬æŒ‡å—ï¼Œæ‚¨å·²ç»å­¦ä¼šäº†ï¼š

1. **ä»»åŠ¡åˆ†æ**: å¦‚ä½•åˆ†ææ–°ä»»åŠ¡çš„éœ€æ±‚
2. **é…ç½®åˆ›å»º**: å¦‚ä½•åˆ›å»ºä»»åŠ¡é…ç½®æ–‡ä»¶
3. **æ¨¡å—å®ç°**: å¦‚ä½•å®ç°æ•°æ®å¤„ç†ã€æ¨¡å‹å’Œè¯„ä¼°æ¨¡å—
4. **ç³»ç»Ÿé›†æˆ**: å¦‚ä½•å°†æ–°ä»»åŠ¡é›†æˆåˆ°ä¸»æ¡†æ¶
5. **æµ‹è¯•éªŒè¯**: å¦‚ä½•æµ‹è¯•å’ŒéªŒè¯æ–°ä»»åŠ¡
6. **éƒ¨ç½²ä½¿ç”¨**: å¦‚ä½•å¯åŠ¨å’Œç›‘æ§æ–°ä»»åŠ¡è®­ç»ƒ

## ğŸ“š æ‰©å±•å»ºè®®

1. **æ·»åŠ æ›´å¤šç±»åˆ«**: æ‰©å±•äº¤é€šæ ‡å¿—ç±»åˆ«
2. **æ”¹è¿›æ¨¡å‹ç»“æ„**: ä½¿ç”¨æ›´å…ˆè¿›çš„æ£€æµ‹æ¶æ„
3. **å¤šæ¨¡æ€èåˆ**: ç»“åˆæ›´å¤šä¼ æ„Ÿå™¨æ•°æ®
4. **æ—¶åºå»ºæ¨¡**: æ·»åŠ æ—¶åºä¿¡æ¯å¤„ç†
5. **éƒ¨ç½²ä¼˜åŒ–**: é’ˆå¯¹æ¨ç†åœºæ™¯ä¼˜åŒ–

---

**æ³¨æ„**: æœ¬æŒ‡å—æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ·»åŠ æ–°ä»»åŠ¡çš„æµç¨‹ç¤ºä¾‹ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡éœ€æ±‚è°ƒæ•´å®ç°ç»†èŠ‚ã€‚
