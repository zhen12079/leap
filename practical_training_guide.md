# LeapAIæ¡†æ¶å®è·µè®­ç»ƒæŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨ä½¿ç”¨LeapAIæ¡†æ¶è¿è¡Œä¸€ä¸ªå®Œæ•´çš„æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒä»»åŠ¡ã€‚æˆ‘ä»¬å°†åŸºäºç°æœ‰çš„é…ç½®æ–‡ä»¶ï¼Œä»ç¯å¢ƒå‡†å¤‡åˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹ã€‚

## ğŸ“‹ å‰ç½®æ¡ä»¶

### 1. ç¯å¢ƒè¦æ±‚
- Python 3.8+
- PyTorch 1.12+
- CUDA 11.0+
- è¶³å¤Ÿçš„GPUå†…å­˜ï¼ˆå»ºè®®16GB+ï¼‰

### 2. æ•°æ®å‡†å¤‡
ç¡®ä¿ä»¥ä¸‹æ•°æ®è·¯å¾„å­˜åœ¨ï¼š
- åŠ¨æ€æ•°æ®é›†ï¼š`/dahuafs/groupdata/Cameraalgorithm/hpa_perception/BEV_Dynamic_target/251001`
- é™æ€æ•°æ®é›†ï¼š`/dahuafs/groupdata/Cameraalgorithm/bev_perception/BEV_Static_map/train_v2.0/v2.8/8650/earlyfusion_v1`
- é¢„è®­ç»ƒæ¨¡å‹ï¼š`/dahuafs/groupdata/share/perception/release/v4.11/torch/v4.11.ckpt`

## ğŸš€ å®è·µæ­¥éª¤

### æ­¥éª¤1ï¼šç¯å¢ƒé…ç½®

#### 1.1 è®¾ç½®ç¯å¢ƒå˜é‡
```bash
export LEAPAI_TASK_CONFIG="projects/perception/configs/lpperception_current_hpa_step1.py"
export RCNUM=1  # èŠ‚ç‚¹æ•°é‡
export GPU_NUM=1  # æ¯èŠ‚ç‚¹GPUæ•°é‡
export my_debug="yes"  # è°ƒè¯•æ¨¡å¼ï¼Œä½¿ç”¨å°æ•°æ®é›†
```

#### 1.2 éªŒè¯é…ç½®æ–‡ä»¶
```python
# éªŒè¯é…ç½®åŠ è½½
from leapai.utils.config import Config
import os

config_path = os.environ["LEAPAI_TASK_CONFIG"]
config = Config.fromfile(config_path)
print(f"ä»»åŠ¡åç§°: {config.job_name}")
print(f"å¯ç”¨LiDAR: {config.enable_lidar}")
print(f"åŠ¨æ€ä»»åŠ¡: {config.dynamic_task}")
print(f"é™æ€ä»»åŠ¡: {config.static_task}")
```

### æ­¥éª¤2ï¼šæ•°æ®éªŒè¯

#### 2.1 æ£€æŸ¥æ•°æ®é›†è·¯å¾„
```python
import os

def check_data_paths(config):
    """æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    missing_paths = []
    
    # æ£€æŸ¥è®­ç»ƒæ•°æ®
    if config.dynamic_task:
        dynamic_path = config.dynamic_train_set_dir
        if not os.path.exists(dynamic_path):
            missing_paths.append(f"åŠ¨æ€è®­ç»ƒæ•°æ®: {dynamic_path}")
    
    if config.static_task:
        static_path = config.static_train_set_dir
        if not os.path.exists(static_path):
            missing_paths.append(f"é™æ€è®­ç»ƒæ•°æ®: {static_path}")
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹
    if config.float_pretrain and not os.path.exists(config.float_pretrain):
        missing_paths.append(f"é¢„è®­ç»ƒæ¨¡å‹: {config.float_pretrain}")
    
    return missing_paths

missing = check_data_paths(config)
if missing:
    print("ç¼ºå°‘ä»¥ä¸‹è·¯å¾„:")
    for path in missing:
        print(f"  - {path}")
else:
    print("æ‰€æœ‰æ•°æ®è·¯å¾„æ£€æŸ¥é€šè¿‡!")
```

#### 2.2 éªŒè¯æ•°æ®åˆ—è¡¨æ–‡ä»¶
```python
def validate_data_lists(config):
    """éªŒè¯æ•°æ®åˆ—è¡¨æ–‡ä»¶"""
    for task_name, task_config in config.train_set_info_path.items():
        if "online" in task_config:
            for data_list in task_config["online"]:
                if os.path.exists(data_list):
                    with open(data_list, 'r') as f:
                        lines = f.readlines()
                    print(f"{task_name} - {os.path.basename(data_list)}: {len(lines)} ä¸ªæ ·æœ¬")
                else:
                    print(f"è­¦å‘Š: {data_list} ä¸å­˜åœ¨")

validate_data_lists(config)
```

### æ­¥éª¤3ï¼šæ¨¡å‹é…ç½®éªŒè¯

#### 3.1 æ£€æŸ¥æ¨¡å‹ç»„ä»¶
```python
def validate_model_config():
    """éªŒè¯æ¨¡å‹é…ç½®"""
    from projects.perception import model_base
    
    print("åŸºç¡€æ¨¡å‹èŠ‚ç‚¹:")
    for node_name in model_base.base_nodes.keys():
        print(f"  - {node_name}")
    
    print(f"\nç›¸æœºé…ç½®: {len(model_base.camera_names)} ä¸ªç›¸æœº")
    print(f"BEVå°ºå¯¸: {model_base.bev_hw}")
    print(f"LiDARèŒƒå›´: {model_base.lidar_range}")

validate_model_config()
```

#### 3.2 éªŒè¯ä»»åŠ¡é…ç½®
```python
def validate_task_configs():
    """éªŒè¯ä»»åŠ¡é…ç½®"""
    from projects.perception import dynamic, static
    
    print("åŠ¨æ€ä»»åŠ¡é…ç½®:")
    print(f"  ç±»åˆ«æ•°é‡: {dynamic.num_classes}")
    print(f"  ç±»åˆ«: {dynamic.class_names}")
    print(f"  æœ€å¤§å¯¹è±¡æ•°: {dynamic.max_objects}")
    
    print("\né™æ€ä»»åŠ¡é…ç½®:")
    print(f"  æ ‡ç­¾ç±»å‹: {static.label_names}")
    print(f"  æŸå¤±æƒé‡: {static.loss_weights}")

validate_task_configs()
```

### æ­¥éª¤4ï¼šè®­ç»ƒå¯åŠ¨

#### 4.1 åˆ›å»ºè®­ç»ƒè„šæœ¬
```python
# run_training.py
import os
import sys
sys.path.append('/dahuafs/userdata/40359/Leapnet_master')

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["LEAPAI_TASK_CONFIG"] = "projects/perception/configs/lpperception_current_hpa_step1.py"
    os.environ["RCNUM"] = "1"
    os.environ["GPU_NUM"] = "1"
    os.environ["my_debug"] = "yes"  # è°ƒè¯•æ¨¡å¼
    
    # å¯¼å…¥å¹¶è¿è¡Œ
    from projects.perception.entry import runner
    
    print("å¼€å§‹è®­ç»ƒ...")
    print(f"é…ç½®æ–‡ä»¶: {os.environ['LEAPAI_TASK_CONFIG']}")
    print(f"GPUæ•°é‡: {os.environ['GPU_NUM']}")
    print(f"è°ƒè¯•æ¨¡å¼: {os.environ['my_debug']}")
    
    # åˆ›å»ºtrainer
    trainer_config = runner
    print(f"è®­ç»ƒå™¨é…ç½®: {trainer_config}")
    
    # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥é…ç½®å’Œå¯åŠ¨è®­ç»ƒ
    print("è®­ç»ƒé…ç½®éªŒè¯å®Œæˆ!")

if __name__ == "__main__":
    main()
```

#### 4.2 è¿è¡Œè®­ç»ƒ
```bash
# æ–¹å¼1: ç›´æ¥è¿è¡ŒPythonè„šæœ¬
python run_training.py

# æ–¹å¼2: ä½¿ç”¨æ¡†æ¶å…¥å£
python -m projects.perception.entry

# æ–¹å¼3: ä½¿ç”¨torch.distributedï¼ˆå¤šGPUï¼‰
python -m torch.distributed.launch \
    --nproc_per_node=1 \
    --nnodes=1 \
    projects/perception/entry.py
```

### æ­¥éª¤5ï¼šç›‘æ§å’Œè°ƒè¯•

#### 5.1 è®­ç»ƒç›‘æ§
```python
def monitor_training():
    """ç›‘æ§è®­ç»ƒè¿‡ç¨‹"""
    import torch
    import time
    
    # æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available():
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"  å†…å­˜: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB")
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    import psutil
    memory = psutil.virtual_memory()
    print(f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨: {memory.percent}% ({memory.used / 1e9:.1f} GB / {memory.total / 1e9:.1f} GB)")

monitor_training()
```

#### 5.2 è°ƒè¯•å·¥å…·
```python
def debug_training_step():
    """è°ƒè¯•è®­ç»ƒæ­¥éª¤"""
    import torch
    from leapai.utils.config import Config
    from projects.perception.entry import MAIN_CFG, TASK_CFGS
    
    print("=== è°ƒè¯•ä¿¡æ¯ ===")
    print(f"ä¸»é…ç½®ä»»åŠ¡æ•°é‡: {len(MAIN_CFG.multi_task_config)}")
    
    for task_name, task_config in TASK_CFGS.items():
        print(f"\nä»»åŠ¡: {task_name}")
        print(f"  èŠ‚ç‚¹æ•°é‡: {len(task_config.nodes) if hasattr(task_config, 'nodes') else 'N/A'}")
        print(f"  æ•°æ®é›†é…ç½®: {'âœ“' if hasattr(task_config, 'get_train_dataset') else 'âœ—'}")
        print(f"  æ‹“æ‰‘é…ç½®: {'âœ“' if hasattr(task_config, 'node_topology') else 'âœ—'}")

debug_training_step()
```

### æ­¥éª¤6ï¼šå¸¸è§é—®é¢˜è§£å†³

#### 6.1 æ•°æ®è·¯å¾„é—®é¢˜
```python
def fix_data_paths():
    """ä¿®å¤å¸¸è§çš„æ•°æ®è·¯å¾„é—®é¢˜"""
    import os
    
    # æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦çš„ç›®å½•
    required_dirs = [
        "./logs",
        "./checkpoints", 
        "./visualization",
        "./data"
    ]
    
    for dir_path in required_dirs:
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)
            print(f"åˆ›å»ºç›®å½•: {dir_path}")

fix_data_paths()
```

#### 6.2 å†…å­˜ä¼˜åŒ–
```python
def optimize_memory_usage():
    """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    import torch
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("GPUç¼“å­˜å·²æ¸…ç†")
    
    # è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
    torch.cuda.set_per_process_memory_fraction(0.9)  # ä½¿ç”¨90%çš„GPUå†…å­˜
    print("å†…å­˜åˆ†é…ç­–ç•¥å·²è®¾ç½®")

optimize_memory_usage()
```

#### 6.3 é…ç½®éªŒè¯
```python
def validate_training_config():
    """éªŒè¯è®­ç»ƒé…ç½®çš„å®Œæ•´æ€§"""
    from leapai.utils.config import Config
    import os
    
    config_path = os.environ.get("LEAPAI_TASK_CONFIG")
    if not config_path:
        raise ValueError("æœªè®¾ç½®LEAPAI_TASK_CONFIGç¯å¢ƒå˜é‡")
    
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    config = Config.fromfile(config_path)
    
    # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
    required_keys = [
        'job_name', 'batch_size', 'max_steps', 'float_lr',
        'multi_task_config', 'train_set_info_path', 'val_set_info_path'
    ]
    
    missing_keys = [key for key in required_keys if key not in config]
    if missing_keys:
        raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„é”®: {missing_keys}")
    
    print("é…ç½®éªŒè¯é€šè¿‡!")
    return config

try:
    config = validate_training_config()
except Exception as e:
    print(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
```

## ğŸ¯ å®Œæ•´è®­ç»ƒç¤ºä¾‹

### ç¤ºä¾‹1ï¼šè°ƒè¯•æ¨¡å¼è®­ç»ƒ
```python
#!/usr/bin/env python3
"""
è°ƒè¯•æ¨¡å¼è®­ç»ƒç¤ºä¾‹
ä½¿ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹
"""

import os
import sys
sys.path.append('/dahuafs/userdata/40359/Leapnet_master')

def setup_debug_environment():
    """è®¾ç½®è°ƒè¯•ç¯å¢ƒ"""
    os.environ["LEAPAI_TASK_CONFIG"] = "projects/perception/configs/lpperception_current_hpa_step1.py"
    os.environ["RCNUM"] = "1"
    os.environ["GPU_NUM"] = "1"
    os.environ["my_debug"] = "yes"
    
    print("=== è°ƒè¯•ç¯å¢ƒè®¾ç½® ===")
    print(f"é…ç½®æ–‡ä»¶: {os.environ['LEAPAI_TASK_CONFIG']}")
    print(f"èŠ‚ç‚¹æ•°: {os.environ['RCNUM']}")
    print(f"GPUæ•°: {os.environ['GPU_NUM']}")
    print(f"è°ƒè¯•æ¨¡å¼: {os.environ['my_debug']}")

def run_debug_training():
    """è¿è¡Œè°ƒè¯•è®­ç»ƒ"""
    try:
        setup_debug_environment()
        
        # éªŒè¯é…ç½®
        config = validate_training_config()
        print(f"ä»»åŠ¡åç§°: {config.job_name}")
        
        # éªŒè¯æ•°æ®è·¯å¾„
        missing_paths = check_data_paths(config)
        if missing_paths:
            print("è­¦å‘Š: å‘ç°ç¼ºå¤±çš„æ•°æ®è·¯å¾„")
            for path in missing_paths:
                print(f"  - {path}")
        
        # ç›‘æ§ç³»ç»Ÿèµ„æº
        monitor_training()
        
        print("\n=== è°ƒè¯•è®­ç»ƒå‡†å¤‡å®Œæˆ ===")
        print("å¯ä»¥å¼€å§‹è¿è¡Œå®é™…è®­ç»ƒäº†!")
        
    except Exception as e:
        print(f"è°ƒè¯•è®­ç»ƒè®¾ç½®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_debug_training()
```

### ç¤ºä¾‹2ï¼šå®Œæ•´è®­ç»ƒæµç¨‹
```python
#!/usr/bin/env python3
"""
å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹
"""

import os
import sys
sys.path.append('/dahuafs/userdata/40359/Leapnet_master')

def setup_production_environment():
    """è®¾ç½®ç”Ÿäº§ç¯å¢ƒ"""
    os.environ["LEAPAI_TASK_CONFIG"] = "projects/perception/configs/lpperception_current_hpa_step1.py"
    os.environ["RCNUM"] = "1"
    os.environ["GPU_NUM"] = "4"  # ä½¿ç”¨4ä¸ªGPU
    # ä¸è®¾ç½®my_debugï¼Œä½¿ç”¨å®Œæ•´æ•°æ®é›†
    
    print("=== ç”Ÿäº§ç¯å¢ƒè®¾ç½® ===")
    print(f"é…ç½®æ–‡ä»¶: {os.environ['LEAPAI_TASK_CONFIG']}")
    print(f"èŠ‚ç‚¹æ•°: {os.environ['RCNUM']}")
    print(f"GPUæ•°: {os.environ['GPU_NUM']}")

def run_production_training():
    """è¿è¡Œç”Ÿäº§è®­ç»ƒ"""
    try:
        setup_production_environment()
        
        # éªŒè¯é…ç½®
        config = validate_training_config()
        print(f"ä»»åŠ¡åç§°: {config.job_name}")
        print(f"æœ€å¤§æ­¥æ•°: {config.max_steps}")
        print(f"æ‰¹æ¬¡å¤§å°: {config.batch_size}")
        
        # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹
        if config.float_pretrain and os.path.exists(config.float_pretrain):
            print(f"é¢„è®­ç»ƒæ¨¡å‹: {config.float_pretrain}")
        else:
            print("è­¦å‘Š: æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹")
        
        print("\n=== ç”Ÿäº§è®­ç»ƒå‡†å¤‡å®Œæˆ ===")
        print("å»ºè®®ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒå‘½ä»¤å¯åŠ¨:")
        print("python -m torch.distributed.launch --nproc_per_node=4 projects/perception/entry.py")
        
    except Exception as e:
        print(f"ç”Ÿäº§è®­ç»ƒè®¾ç½®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_production_training()
```

## ğŸ”§ é«˜çº§é…ç½®

### å¤šGPUè®­ç»ƒ
```bash
# 4GPUè®­ç»ƒ
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    --nnodes=1 \
    --node_rank=0 \
    --master_addr="localhost" \
    --master_port=12345 \
    projects/perception/entry.py

# å¤šèŠ‚ç‚¹è®­ç»ƒ (èŠ‚ç‚¹1)
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=0 \
    --master_addr="192.168.1.100" \
    --master_port=12345 \
    projects/perception/entry.py

# å¤šèŠ‚ç‚¹è®­ç»ƒ (èŠ‚ç‚¹2)
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=1 \
    --master_addr="192.168.1.100" \
    --master_port=12345 \
    projects/perception/entry.py
```

### æ··åˆç²¾åº¦è®­ç»ƒ
```python
# åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ 
precision = "16-mixed"  # ä½¿ç”¨æ··åˆç²¾åº¦
use_backbone_amp = True  # Backboneä½¿ç”¨AMP
```

### æ¢¯åº¦ç´¯ç§¯
```python
# åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´
accumulate_grad_batches = 2  # æ¢¯åº¦ç´¯ç§¯2æ­¥
batch_size = 8  # å‡å°æ‰¹æ¬¡å¤§å°
# æœ‰æ•ˆæ‰¹æ¬¡å¤§å° = 8 * 2 = 16
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### TensorBoardç›‘æ§
```python
# å¯åŠ¨TensorBoard
tensorboard --logdir=./logs --port=6006

# åœ¨é…ç½®ä¸­å¯ç”¨TensorBoard
logger = dict(
    type="TensorBoardLogger",
    save_dir="./logs",
    name=config.job_name,
)
```

### è®­ç»ƒè„šæœ¬ç›‘æ§
```python
def monitor_training_progress(log_file="./logs/training.log"):
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    import re
    from datetime import datetime
    
    if not os.path.exists(log_file):
        print(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return
    
    with open(log_file, 'r') as f:
        lines = f.readlines()
    
    # è§£ææŸå¤±ä¿¡æ¯
    losses = []
    for line in lines[-100:]:  # æœ€è¿‘100è¡Œ
        if "loss" in line.lower():
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æŸå¤±å€¼
            match = re.search(r'loss:\s*([\d.]+)', line)
            if match:
                losses.append(float(match.group(1)))
    
    if losses:
        print(f"æœ€è¿‘æŸå¤±è¶‹åŠ¿: {losses[-10:]}")
        print(f"å½“å‰æŸå¤±: {losses[-1]:.4f}")
        print(f"æŸå¤±å˜åŒ–: {losses[-1] - losses[-10]:.4f}")

# ä½¿ç”¨ç¤ºä¾‹
monitor_training_progress()
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### 1. CUDAå†…å­˜ä¸è¶³
```python
# è§£å†³æ–¹æ¡ˆ1: å‡å°æ‰¹æ¬¡å¤§å°
batch_size = 4  # ä»16å‡å°‘åˆ°4

# è§£å†³æ–¹æ¡ˆ2: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
from torch.utils.checkpoint import checkpoint

# è§£å†³æ–¹æ¡ˆ3: æ¸…ç†GPUç¼“å­˜
torch.cuda.empty_cache()
```

#### 2. æ•°æ®åŠ è½½é”™è¯¯
```python
# æ£€æŸ¥æ•°æ®è·¯å¾„
def debug_data_loading():
    """è°ƒè¯•æ•°æ®åŠ è½½"""
    from projects.perception.dataset import LeapDataset
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®é›†å®ä¾‹
    sample_case = {
        "case_path": "/path/to/sample/case.json",
        "scene_name": "test_scene"
    }
    
    try:
        dataset = LeapDataset(
            case_info=sample_case,
            camera_names=["front_wide", "front_left", "front_right"],
            pipeline=[],
            task_name="dynamic"
        )
        print("æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")

debug_data_loading()
```

#### 3. é…ç½®æ–‡ä»¶é”™è¯¯
```python
def debug_config_loading():
    """è°ƒè¯•é…ç½®åŠ è½½"""
    import os
    from leapai.utils.config import Config
    
    config_path = os.environ.get("LEAPAI_TASK_CONFIG")
    if not config_path:
        print("é”™è¯¯: æœªè®¾ç½®LEAPAI_TASK_CONFIG")
        return
    
    try:
        config = Config.fromfile(config_path)
        print("é…ç½®åŠ è½½æˆåŠŸ")
        print(f"ä»»åŠ¡åç§°: {config.job_name}")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        required_keys = ['batch_size', 'max_steps', 'multi_task_config']
        for key in required_keys:
            if hasattr(config, key):
                print(f"âœ“ {key}: {getattr(config, key)}")
            else:
                print(f"âœ— {key}: ç¼ºå¤±")
                
    except Exception as e:
        print(f"é…ç½®åŠ è½½å¤±è´¥: {e}")

debug_config_loading()
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–
```python
# å¢åŠ æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹
num_workers = {
    "dynamic": {"train": 8, "val": 4},
    "static": {"train": 8, "val": 4},
}

# å¯ç”¨æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹
persistent_workers = True

# ä½¿ç”¨pin_memory
pin_memory = True
```

### 2. æ¨¡å‹ä¼˜åŒ–
```python
# ä½¿ç”¨ç¼–è¯‘ä¼˜åŒ– (PyTorch 2.0+)
model = torch.compile(model)

# ä½¿ç”¨æ›´é«˜æ•ˆçš„backbone
# ä¾‹å¦‚ï¼šå°†ResNet34æ›¿æ¢ä¸ºEfficientNet
```

### 3. è®­ç»ƒç­–ç•¥ä¼˜åŒ–
```python
# å­¦ä¹ ç‡è°ƒåº¦
lr_scheduler = "cosine"  # ä½™å¼¦é€€ç«

# é¢„çƒ­ç­–ç•¥
warmup_steps = 1000

# æ¢¯åº¦è£å‰ª
gradient_clip_val = 35.0
```

## ğŸ¯ æ€»ç»“

æœ¬å®è·µæŒ‡å—æ¶µç›–äº†ï¼š

1. **ç¯å¢ƒé…ç½®**: è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡å’Œä¾èµ–
2. **æ•°æ®éªŒè¯**: ç¡®ä¿æ•°æ®è·¯å¾„å’Œæ ¼å¼æ­£ç¡®
3. **æ¨¡å‹é…ç½®**: éªŒè¯æ¨¡å‹ç»„ä»¶å’Œä»»åŠ¡é…ç½®
4. **è®­ç»ƒå¯åŠ¨**: å¤šç§è®­ç»ƒå¯åŠ¨æ–¹å¼
5. **ç›‘æ§è°ƒè¯•**: å®æ—¶ç›‘æ§å’Œè°ƒè¯•
6. **æ€§èƒ½ä¼˜åŒ–**: æå‡è®­ç»ƒæ•ˆç‡çš„å„ç§æŠ€å·§
7. **æ•…éšœæ’é™¤**: å¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ

## ğŸ“š ä¸‹ä¸€æ­¥

å®Œæˆå®è·µè®­ç»ƒåï¼Œæ‚¨å¯ä»¥ï¼š

1. **å°è¯•ä¸åŒé…ç½®**: ä¿®æ”¹è¶…å‚æ•°å’Œæ¨¡å‹æ¶æ„
2. **æ·»åŠ æ–°ä»»åŠ¡**: åŸºäºç°æœ‰æ¡†æ¶æ·»åŠ æ–°çš„æ„ŸçŸ¥ä»»åŠ¡
3. **ä¼˜åŒ–æ€§èƒ½**: è¿›ä¸€æ­¥ä¼˜åŒ–è®­ç»ƒå’Œæ¨ç†æ€§èƒ½
4. **éƒ¨ç½²åº”ç”¨**: å°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²åˆ°å®é™…åº”ç”¨ä¸­

## ğŸ”— ç›¸å…³èµ„æº

- [LeapAIå­¦ä¹ æŒ‡å—](LeapAI_Learning_Guide.md)
- [å¿«é€Ÿå¼€å§‹æŒ‡å—](Quick_Start_Guide.md)
- [é…ç½®ç³»ç»Ÿè¯¦è§£](config_loading_troubleshooting.md)
- [åˆ†å¸ƒå¼è®­ç»ƒæŒ‡å—](distributed_training_detailed_analysis.md)

---

**æ³¨æ„**: æœ¬æŒ‡å—åŸºäºLeapAIæ¡†æ¶çš„å½“å‰ç‰ˆæœ¬ç¼–å†™ï¼ŒæŸäº›é…ç½®å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“ç¯å¢ƒè¿›è¡Œè°ƒæ•´ã€‚å»ºè®®åœ¨å®é™…ä½¿ç”¨å‰å…ˆåœ¨è°ƒè¯•æ¨¡å¼ä¸‹éªŒè¯é…ç½®çš„æ­£ç¡®æ€§ã€‚
