# LeapAIåˆ†å¸ƒå¼è®­ç»ƒå’Œéƒ¨ç½²æœºåˆ¶è¯¦ç»†åˆ†æ

## ğŸ“‹ å­¦ä¹ æ¦‚è§ˆ

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æLeapAIæ¡†æ¶çš„åˆ†å¸ƒå¼è®­ç»ƒå’Œéƒ¨ç½²æœºåˆ¶ï¼ŒåŒ…æ‹¬åˆ†å¸ƒå¼ç¯å¢ƒç®¡ç†ã€æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€å¤šä»»åŠ¡åè°ƒç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒç»„ä»¶åˆ†æ

### 1. åˆ†å¸ƒå¼ç¯å¢ƒç®¡ç† - [`leapai/distributed.py`](../leapai/distributed.py)

#### 1.1 è£…é¥°å™¨å‡½æ•°

##### rank_zero_onlyè£…é¥°å™¨ (ç¬¬9-15è¡Œ)
```python
def rank_zero_only(fn):
    @wraps(fn)
    def inner(*args, **kwargs):
        if int(os.environ.get("LOCAL_RANK", -100)) in [-100, 0]:
            return fn(*args, **kwargs)
    return inner
```

**åŠŸèƒ½ç‰¹ç‚¹**:
- **æœ¬åœ°ç§©é™åˆ¶**: åªåœ¨æœ¬åœ°ç§©ä¸º0æˆ–-100æ—¶æ‰§è¡Œå‡½æ•°
- **æ—¥å¿—æ§åˆ¶**: ç”¨äºæ§åˆ¶æ—¥å¿—è¾“å‡ºï¼Œé¿å…å¤šè¿›ç¨‹é‡å¤è¾“å‡º
- **ç¯å¢ƒå˜é‡**: é€šè¿‡LOCAL_RANKç¯å¢ƒå˜é‡è·å–è¿›ç¨‹ç§©
- **é»˜è®¤å€¼**: -100è¡¨ç¤ºéåˆ†å¸ƒå¼ç¯å¢ƒ

##### global_rank_zero_onlyè£…é¥°å™¨ (ç¬¬44-51è¡Œ)
```python
def global_rank_zero_only(fn):
    @wraps(fn)
    def inner(*args, **kwargs):
        grank, _ = get_dist_info()
        if grank == 0:
            return fn(*args, **kwargs)
    return inner
```

**åŠŸèƒ½ç‰¹ç‚¹**:
- **å…¨å±€ç§©é™åˆ¶**: åªåœ¨å…¨å±€ç§©ä¸º0æ—¶æ‰§è¡Œå‡½æ•°
- **åˆ†å¸ƒå¼æ„ŸçŸ¥**: é€šè¿‡get_dist_infoè·å–åˆ†å¸ƒå¼ä¿¡æ¯
- **ä¸»è¿›ç¨‹æ§åˆ¶**: ç¡®ä¿åªæœ‰ä¸»è¿›ç¨‹æ‰§è¡Œç‰¹å®šæ“ä½œ

#### 1.2 è®¾å¤‡ç®¡ç†

##### get_current_deviceå‡½æ•° (ç¬¬18-24è¡Œ)
```python
def get_current_device():
    if torch.cuda.is_available():
        cuda_id = os.environ.get("LOCAL_RANK", 0)
        device = torch.device(f"cuda:{cuda_id}")
    else:
        device = torch.device("cpu")
    return device
```

**è®¾å¤‡é€‰æ‹©é€»è¾‘**:
- **CUDAå¯ç”¨**: ä½¿ç”¨LOCAL_RANKæŒ‡å®šçš„GPU
- **CUDAä¸å¯ç”¨**: å›é€€åˆ°CPU
- **è‡ªåŠ¨åˆ†é…**: æ ¹æ®è¿›ç¨‹ç§©è‡ªåŠ¨åˆ†é…GPUè®¾å¤‡

#### 1.3 åˆ†å¸ƒå¼çŠ¶æ€ç®¡ç†

##### dist_initå‡½æ•° (ç¬¬27-31è¡Œ)
```python
def dist_init():
    initialized = False
    if dist.is_available():
        initialized = dist.is_initialized()
    return initialized
```

**çŠ¶æ€æ£€æŸ¥**:
- **å¯ç”¨æ€§æ£€æŸ¥**: æ£€æŸ¥åˆ†å¸ƒå¼æ˜¯å¦å¯ç”¨
- **åˆå§‹åŒ–æ£€æŸ¥**: æ£€æŸ¥åˆ†å¸ƒå¼æ˜¯å¦å·²åˆå§‹åŒ–
- **è¿”å›çŠ¶æ€**: è¿”å›åˆå§‹åŒ–çŠ¶æ€

##### get_dist_infoå‡½æ•° (ç¬¬34-41è¡Œ)
```python
def get_dist_info(process_group=None) -> Tuple[int, int]:
    if dist_init():
        global_rank = dist.get_rank(process_group)
        world_size = dist.get_world_size(process_group)
    else:
        global_rank = 0
        world_size = 1
    return global_rank, world_size
```

**ä¿¡æ¯è·å–**:
- **åˆ†å¸ƒå¼ç¯å¢ƒ**: è·å–å…¨å±€ç§©å’Œä¸–ç•Œå¤§å°
- **å•æœºç¯å¢ƒ**: è¿”å›ç§©0å’Œä¸–ç•Œå¤§å°1
- **è¿›ç¨‹ç»„æ”¯æŒ**: æ”¯æŒæŒ‡å®šè¿›ç¨‹ç»„

#### 1.4 GPUèµ„æºç®¡ç†

##### reset_gpuå‡½æ•° (ç¬¬54-57è¡Œ)
```python
def reset_gpu():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    torch.cuda.init()
```

**é‡ç½®æ“ä½œ**:
- **æ¸…ç©ºç¼“å­˜**: é‡Šæ”¾GPUå†…å­˜ç¼“å­˜
- **åŒæ­¥æ“ä½œ**: ç­‰å¾…æ‰€æœ‰GPUæ“ä½œå®Œæˆ
- **é‡æ–°åˆå§‹åŒ–**: é‡æ–°åˆå§‹åŒ–CUDA

### 2. ç¯å¢ƒä¿¡æ¯æ”¶é›† - [`leapai/env.py`](../leapai/env.py)

#### 2.1 collect_envå‡½æ•° (ç¬¬11-104è¡Œ)

##### ç³»ç»Ÿä¿¡æ¯æ”¶é›†
```python
env_info = {}
env_info["sys.platform"] = sys.platform
env_info["Python"] = sys.version.replace("\n", "")
```

##### CUDAç¯å¢ƒæ£€æµ‹
```python
cuda_available = torch.cuda.is_available()
env_info["CUDA available"] = cuda_available

if cuda_available:
    devices = defaultdict(list)
    for k in range(torch.cuda.device_count()):
        devices[torch.cuda.get_device_name(k)].append(str(k))
    for name, device_ids in devices.items():
        env_info["GPU " + ",".join(device_ids)] = name
```

**GPUä¿¡æ¯æ”¶é›†**:
- **è®¾å¤‡æ£€æµ‹**: æ£€æµ‹æ‰€æœ‰å¯ç”¨GPUè®¾å¤‡
- **è®¾å¤‡åˆ†ç»„**: æŒ‰è®¾å¤‡åç§°åˆ†ç»„GPU
- **è¯¦ç»†ä¿¡æ¯**: è®°å½•æ¯ä¸ªGPUçš„å‹å·å’ŒID

##### ç¼–è¯‘å™¨ä¿¡æ¯
```python
try:
    import sysconfig
    cc = sysconfig.get_config_var("CC")
    if cc:
        cc_info = subprocess.check_output(f"{cc} --version", shell=True)
        env_info["GCC"] = cc_info.decode("utf-8").partition("\n")[0].strip()
```

**ç¼–è¯‘å™¨æ£€æµ‹**:
- **GCCæ£€æµ‹**: æ£€æµ‹GCCç¼–è¯‘å™¨ç‰ˆæœ¬
- **MSVCæ£€æµ‹**: Windowsä¸‹æ£€æµ‹MSVCç‰ˆæœ¬
- **é”™è¯¯å¤„ç†**: ç¼–è¯‘å™¨ä¸å¯ç”¨æ—¶æ ‡è®°ä¸º"n/a"

### 3. åˆ†å¸ƒå¼æ•°æ®é‡‡æ · - [`leapai/data/sampler/rank_split_sampler.py`](../leapai/data/sampler/rank_split_sampler.py)

#### 3.1 RankSplitSamplerç±» (ç¬¬15-151è¡Œ)

##### æ ¸å¿ƒç‰¹æ€§
```python
@LEAP_OBJECTS.register_module()
class RankSplitSampler(DistributedSampler[T_co]):
    """
    Distributed sampler that supports user-defined indices.
    """
```

**è®¾è®¡ç‰¹ç‚¹**:
- **ç»§æ‰¿DistributedSampler**: åŸºäºPyTorchåˆ†å¸ƒå¼é‡‡æ ·å™¨
- **ç´¢å¼•æ§åˆ¶**: æ”¯æŒç”¨æˆ·å®šä¹‰çš„ç´¢å¼•èŒƒå›´
- **ä¸‹é‡‡æ ·**: æ”¯æŒæ•°æ®ä¸‹é‡‡æ ·
- **æµå¼å¤„ç†**: æ”¯æŒæµå¼æ•°æ®åŠ è½½

##### åˆå§‹åŒ–å‚æ•° (ç¬¬43-82è¡Œ)
```python
def __init__(
    self,
    dataset: ConcatDataset,
    left_index: int,
    right_index: int,
    rank_sample: int,
    down_sample_ratio: int = 1,
    use_streaming: bool = False,
    batch_size: int = None,
    *,
    num_replicas: Optional[int] = None,
    rank: Optional[int] = None,
    shuffle: bool = True,
    seed: int = 0,
    drop_last: bool = False,
) -> None:
```

**å‚æ•°è¯´æ˜**:
- **dataset**: ConcatDatasetç±»å‹çš„æ•°æ®é›†
- **left_index/right_index**: ç´¢å¼•èŒƒå›´æ§åˆ¶
- **rank_sample**: æ¯ä¸ªç§©çš„æ ·æœ¬æ•°
- **down_sample_ratio**: ä¸‹é‡‡æ ·æ¯”ä¾‹
- **use_streaming**: æ˜¯å¦å¯ç”¨æµå¼å¤„ç†
- **batch_size**: æ‰¹æ¬¡å¤§å°ï¼ˆæµå¼å¤„ç†æ—¶å¿…éœ€ï¼‰

##### ç´¢å¼•ç”Ÿæˆç­–ç•¥ (ç¬¬84-128è¡Œ)
```python
def get_epoch_indices(self):
    final_indices = []
    last_length = 0
    dataset_num = len(self.dataset.datasets)
    dataset_indices = {}
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆç´¢å¼•
    for i in range(dataset_num):
        dataset = self.dataset.datasets[i]
        length = len(dataset)
        indices = list(range(last_length, last_length + length))
        if i == 0:
            indices = indices[self.left_index :]
        if i == dataset_num - 1:
            indices = indices[: self.right_index + 1]
        if self.shuffle and not self.use_streaming:
            indices = self.shuffle_indices(indices)
        indices = indices[:: self.down_sample_ratio]
        dataset_indices[i] = indices
        last_length += length
```

**ç´¢å¼•ç”Ÿæˆé€»è¾‘**:
1. **èŒƒå›´æ§åˆ¶**: æ ¹æ®left_indexå’Œright_indexæˆªå–ç´¢å¼•
2. **éšæœºæ‰“ä¹±**: éæµå¼æ¨¡å¼ä¸‹éšæœºæ‰“ä¹±ç´¢å¼•
3. **ä¸‹é‡‡æ ·**: æŒ‰æ¯”ä¾‹ä¸‹é‡‡æ ·ç´¢å¼•
4. **æ•°æ®é›†ç®¡ç†**: ç®¡ç†å¤šä¸ªæ•°æ®é›†çš„ç´¢å¼•

##### æµå¼å¤„ç†é€»è¾‘ (ç¬¬104-121è¡Œ)
```python
if self.use_streaming:
    for start in range(0, dataset_num, self.batch_size):
        tmp = dataset_idx[start : start + self.batch_size]
        while tmp:
            for set_i in tmp:
                indices = dataset_indices[set_i]
                if len(indices) > 0:
                    final_indices.append(indices.pop(0))
                else:
                    tmp.remove(set_i)
```

**æµå¼å¤„ç†ç‰¹ç‚¹**:
- **æ‰¹æ¬¡å¤„ç†**: æŒ‰æ‰¹æ¬¡å¤„ç†æ•°æ®é›†
- **è½®è¯¢æœºåˆ¶**: è½®è¯¢å„ä¸ªæ•°æ®é›†
- **åŠ¨æ€è°ƒæ•´**: æ•°æ®é›†è€—å°½æ—¶åŠ¨æ€è°ƒæ•´

#### 3.2 RankSplitCaseSamplerç±» (ç¬¬154-175è¡Œ)

##### ç”¨é€”å’Œè®¾è®¡
```python
@LEAP_OBJECTS.register_module()
class RankSplitCaseSampler(DistributedSampler[T_co]):
    """
    must split case data into ranks in DataModule.
    this sampler just work as batched SequenceSampler
    just for testing now
    """
```

**è®¾è®¡ç‰¹ç‚¹**:
- **æ¡ˆä¾‹é‡‡æ ·**: ä¸“é—¨ç”¨äºæ¡ˆä¾‹æ•°æ®çš„é‡‡æ ·
- **æ‰¹æ¬¡åºåˆ—**: æŒ‰æ‰¹æ¬¡é¡ºåºé‡‡æ ·
- **æµ‹è¯•ç”¨é€”**: ä¸»è¦ç”¨äºæµ‹è¯•åœºæ™¯

### 4. ç»„åˆæ•°æ®åŠ è½½å™¨ - [`leapai/data/dataloader/combined_dataloader.py`](../leapai/data/dataloader/combined_dataloader.py)

#### 4.1 BaseCombinedLoaderç±» (ç¬¬10-17è¡Œ)

##### æ—¶é—´ç»Ÿè®¡åŠŸèƒ½
```python
@LEAP_OBJECTS.register_module()
class BaseCombinedLoader(CombinedLoader):
    def __next__(self) -> _ITERATOR_RETURN:
        start = time.monotonic()
        batch, batch_id, dataloader_id = super().__next__()
        end = time.monotonic()
        batch["_data_time_cost"] = end - start
        return batch, batch_id, dataloader_id
```

**åŠŸèƒ½å¢å¼º**:
- **æ—¶é—´ç»Ÿè®¡**: è®°å½•æ•°æ®åŠ è½½æ—¶é—´
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§æ•°æ®åŠ è½½æ€§èƒ½
- **ç»§æ‰¿æ‰©å±•**: åŸºäºLightningçš„CombinedLoaderæ‰©å±•

### 5. ä¸»å…¥å£ç¨‹åº - [`tools/main.py`](../tools/main.py)

#### 5.1 å‚æ•°è§£æ (ç¬¬21-34è¡Œ)

##### åˆ†å¸ƒå¼ç›¸å…³å‚æ•°
```python
parser.add_argument("--local-rank", type=int, default=0)
```

**å‚æ•°è¯´æ˜**:
- **local-rank**: æœ¬åœ°è¿›ç¨‹ç§©
- **é»˜è®¤å€¼**: é»˜è®¤ä¸º0ï¼ˆä¸»è¿›ç¨‹ï¼‰

#### 5.2 ä¸»å‡½æ•°æ‰§è¡Œæµç¨‹ (ç¬¬37-97è¡Œ)

##### ç¯å¢ƒåˆå§‹åŒ– (ç¬¬39-54è¡Œ)
```python
def main(args):
    seed_everything(args.seed)
    cfg_path = args.config
    cfg = Config.fromfile(cfg_path)
    reset_gpu()  # é‡ç½® GPU çŠ¶æ€
    ckpt = args.ckpt if args.ckpt else cfg.get("float_pretrain", None)
    resume_ckpt = args.resume if args.resume else cfg.get("resume_ckpt", None)

    init_num_threads(args.num_threads)  # è®¾ç½® CPU çº¿ç¨‹æ•°

    env_info_dict = collect_env()
    env_info = "\n".join([(f"{k}: {v}") for k, v in env_info_dict.items()])
    dash_line = "-" * 79 + "\n"
    rank_zero_info(
        "Environment info:\n" + dash_line + env_info + "\n" + dash_line
    )
```

**åˆå§‹åŒ–æ­¥éª¤**:
1. **éšæœºç§å­**: è®¾ç½®å…¨å±€éšæœºç§å­
2. **é…ç½®åŠ è½½**: åŠ è½½ä¸»é…ç½®æ–‡ä»¶
3. **GPUé‡ç½®**: é‡ç½®GPUçŠ¶æ€
4. **çº¿ç¨‹è®¾ç½®**: è®¾ç½®CPUçº¿ç¨‹æ•°
5. **ç¯å¢ƒä¿¡æ¯**: æ”¶é›†å’Œæ˜¾ç¤ºç¯å¢ƒä¿¡æ¯

##### è®­ç»ƒå™¨æ„å»ºå’Œæ‰§è¡Œ (ç¬¬56-92è¡Œ)
```python
with RegistryContext():
    with_val = args.with_val
    runner_cfg = cfg.runner
    state = args.state
    if state == "train" and not with_val:
        runner_cfg["num_sanity_val_steps"] = 0
        runner_cfg["limit_val_batches"] = 0
    if state == "val":
        runner_cfg["val_check_interval"] = None
    runner = build_from_registry(runner_cfg)
    model = build_from_registry(cfg.graph_model)
    if ckpt:
        model = load_checkpoint(
            model,
            ckpt,
            allow_miss=True,
            allow_unexpect=True,
            verbose=args.verbose,
        )
    data_module = build_from_registry(cfg.data_module)
    
    # æ‰§è¡Œä¸åŒçŠ¶æ€
    if state == "val":
        runner.validate(model, data_module)
    elif state == "test":
        runner.test(model, data_module)
    elif state == "predict":
        runner.predict(model, data_module)
    elif state == "train":
        runner.fit(
            model=model, datamodule=data_module, ckpt_path=resume_ckpt
        )
```

**æ‰§è¡Œæµç¨‹**:
1. **æ³¨å†Œä¸Šä¸‹æ–‡**: åˆ›å»ºæ³¨å†Œè¡¨ä¸Šä¸‹æ–‡
2. **è®­ç»ƒå™¨é…ç½®**: æ ¹æ®çŠ¶æ€è°ƒæ•´è®­ç»ƒå™¨é…ç½®
3. **ç»„ä»¶æ„å»º**: æ„å»ºè®­ç»ƒå™¨ã€æ¨¡å‹ã€æ•°æ®æ¨¡å—
4. **æ£€æŸ¥ç‚¹åŠ è½½**: åŠ è½½é¢„è®­ç»ƒæƒé‡
5. **çŠ¶æ€æ‰§è¡Œ**: æ ¹æ®çŠ¶æ€æ‰§è¡Œç›¸åº”æ“ä½œ

### 6. æ„ŸçŸ¥é¡¹ç›®åˆ†å¸ƒå¼é…ç½® - [`projects/perception/entry.py`](../projects/perception/entry.py)

#### 6.1 åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ (ç¬¬46-47è¡Œ)
```python
num_machines = int(os.environ.get("NNODES", 1))
devices_id = MAIN_CFG.get("devices_id", "auto")
```

**åˆ†å¸ƒå¼é…ç½®**:
- **NNODES**: èŠ‚ç‚¹æ•°é‡ç¯å¢ƒå˜é‡
- **devices_id**: GPUè®¾å¤‡é…ç½®
- **è‡ªåŠ¨æ£€æµ‹**: æ”¯æŒè‡ªåŠ¨è®¾å¤‡æ£€æµ‹

#### 6.2 æ•°æ®é‡‡æ ·å™¨é…ç½® (ç¬¬133-139è¡Œ)
```python
train_sampler = dict(
    type="RankSplitSampler",
    shuffle=True,
    down_sample_ratio=MAIN_CFG.down_sample_ratio[task_name]["train"],
    use_streaming=MAIN_CFG.use_streaming[task_name],
    batch_size=MAIN_CFG.batch_sizes[task_name]["train"],
)
```

**é‡‡æ ·å™¨ç‰¹ç‚¹**:
- **åˆ†å¸ƒå¼é‡‡æ ·**: ä½¿ç”¨RankSplitSampler
- **ä¸‹é‡‡æ ·æ”¯æŒ**: æ”¯æŒæ•°æ®ä¸‹é‡‡æ ·
- **æµå¼å¤„ç†**: æ”¯æŒæµå¼æ•°æ®åŠ è½½
- **æ‰¹æ¬¡æ§åˆ¶**: çµæ´»çš„æ‰¹æ¬¡å¤§å°æ§åˆ¶

#### 6.3 è®­ç»ƒå™¨åˆ†å¸ƒå¼é…ç½® (ç¬¬567-608è¡Œ)
```python
runner = dict(
    type=L.Trainer,
    accelerator=base.accelerator,
    strategy=base.strategy,
    devices=devices_id,
    num_nodes=num_machines,
    precision=precision,
    logger=base.loggers,
    callbacks=callbacks,
    # ... å…¶ä»–é…ç½®
    use_distributed_sampler=use_distributed_sampler,
    sync_batchnorm=False,
    reload_dataloaders_every_n_epochs=1,
)
```

**åˆ†å¸ƒå¼ç‰¹æ€§**:
- **å¤šèŠ‚ç‚¹æ”¯æŒ**: æ”¯æŒå¤šèŠ‚ç‚¹è®­ç»ƒ
- **åˆ†å¸ƒå¼é‡‡æ ·å™¨**: è‡ªåŠ¨é…ç½®åˆ†å¸ƒå¼é‡‡æ ·å™¨
- **åŒæ­¥æ‰¹å½’ä¸€åŒ–**: å¯é€‰çš„åŒæ­¥æ‰¹å½’ä¸€åŒ–
- **æ•°æ®é‡è½½**: å®šæœŸé‡æ–°åŠ è½½æ•°æ®åŠ è½½å™¨

## ğŸ¯ åˆ†å¸ƒå¼è®­ç»ƒæ¶æ„

### 1. æ•´ä½“æ¶æ„å›¾
```mermaid
graph TD
    A[ä¸»å…¥å£ tools/main.py] --> B[ç¯å¢ƒåˆå§‹åŒ–]
    B --> C[åˆ†å¸ƒå¼é…ç½®]
    C --> D[è®­ç»ƒå™¨æ„å»º]
    D --> E[æ•°æ®æ¨¡å—æ„å»º]
    E --> F[æ¨¡å‹æ„å»º]
    F --> G[åˆ†å¸ƒå¼æ‰§è¡Œ]
    
    C --> C1[ç¯å¢ƒå˜é‡æ£€æµ‹]
    C --> C2[è®¾å¤‡åˆ†é…]
    C --> C3[è¿›ç¨‹ç»„åˆå§‹åŒ–]
    
    E --> E1[RankSplitSampler]
    E --> E2[CombinedLoader]
    E --> E3[åˆ†å¸ƒå¼æ•°æ®åŠ è½½]
    
    G --> G1[æ•°æ®å¹¶è¡Œ]
    G --> G2[æ¢¯åº¦åŒæ­¥]
    G --> G3[å¤šä»»åŠ¡åè°ƒ]
```

### 2. æ•°æ®æµæ¶æ„
```mermaid
graph LR
    A[åŸå§‹æ•°æ®] --> B[RankSplitSampler]
    B --> C[æ•°æ®åˆ†ç‰‡]
    C --> D[CombinedLoader]
    D --> E[å¤šä»»åŠ¡æ‰¹æ¬¡]
    E --> F[NodeGraph]
    F --> G[æ¢¯åº¦è®¡ç®—]
    G --> H[æ¢¯åº¦åŒæ­¥]
    H --> I[å‚æ•°æ›´æ–°]
```

## ğŸ“Š æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§

### 1. åˆ†å¸ƒå¼ç¯å¢ƒç®¡ç†
- **è‡ªåŠ¨æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹åˆ†å¸ƒå¼ç¯å¢ƒ
- **è®¾å¤‡åˆ†é…**: æ™ºèƒ½çš„GPUè®¾å¤‡åˆ†é…
- **è¿›ç¨‹ç®¡ç†**: å®Œå–„çš„è¿›ç¨‹ç§©ç®¡ç†
- **èµ„æºç›‘æ§**: GPUèµ„æºå’Œç¯å¢ƒä¿¡æ¯ç›‘æ§

### 2. æ•°æ®å¹¶è¡Œç­–ç•¥
- **æ™ºèƒ½é‡‡æ ·**: åŸºäºç§©çš„æ™ºèƒ½æ•°æ®é‡‡æ ·
- **è´Ÿè½½å‡è¡¡**: ç¡®ä¿å„è¿›ç¨‹è´Ÿè½½å‡è¡¡
- **æµå¼å¤„ç†**: æ”¯æŒå¤§è§„æ¨¡æ•°æ®æµå¼å¤„ç†
- **æ€§èƒ½ç›‘æ§**: æ•°æ®åŠ è½½æ€§èƒ½å®æ—¶ç›‘æ§

### 3. å¤šä»»åŠ¡åè°ƒ
- **ä»»åŠ¡è·¯ç”±**: æ™ºèƒ½çš„ä»»åŠ¡è·¯ç”±å’Œåˆ†å‘
- **æ¢¯åº¦åŒæ­¥**: å¤šä»»åŠ¡æ¢¯åº¦åŒæ­¥ç­–ç•¥
- **æŸå¤±åŠ æƒ**: ä»»åŠ¡æŸå¤±æƒé‡ç®¡ç†
- **æ‰§è¡Œåè°ƒ**: è®­ç»ƒ/éªŒè¯/é¢„æµ‹é˜¶æ®µåè°ƒ

### 4. å®¹é”™å’Œæ¢å¤
- **æ£€æŸ¥ç‚¹**: åˆ†å¸ƒå¼æ£€æŸ¥ç‚¹ç®¡ç†
- **æ•…éšœæ¢å¤**: è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œæ¢å¤
- **çŠ¶æ€åŒæ­¥**: åˆ†å¸ƒå¼çŠ¶æ€åŒæ­¥æœºåˆ¶
- **èµ„æºæ¸…ç†**: èµ„æºè‡ªåŠ¨æ¸…ç†å’Œé‡Šæ”¾

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. å•æœºå¤šGPUè®­ç»ƒ
```bash
# ä½¿ç”¨torchrunå¯åŠ¨å•æœºå¤šGPUè®­ç»ƒ
torchrun --nproc_per_node=4 \
    tools/main.py \
    --config projects/perception/configs/lpperception_current.py \
    --state train \
    --local-rank 0
```

### 2. å¤šèŠ‚ç‚¹è®­ç»ƒ
```bash
# èŠ‚ç‚¹0
torchrun --nnodes=2 --node_rank=0 \
    --master_addr="192.168.1.100" --master_port=12345 \
    --nproc_per_node=4 \
    tools/main.py \
    --config projects/perception/configs/lpperception_current.py \
    --state train

# èŠ‚ç‚¹1
torchrun --nnodes=2 --node_rank=1 \
    --master_addr="192.168.1.100" --master_port=12345 \
    --nproc_per_node=4 \
    tools/main.py \
    --config projects/perception/configs/lpperception_current.py \
    --state train
```

### 3. åˆ†å¸ƒå¼é…ç½®ç¤ºä¾‹
```python
# é…ç½®æ–‡ä»¶ä¸­çš„åˆ†å¸ƒå¼è®¾ç½®
MAIN_CFG = {
    "devices_id": "auto",  # è‡ªåŠ¨æ£€æµ‹GPU
    "num_machines": 2,      # èŠ‚ç‚¹æ•°é‡
    "batch_sizes": {
        "dynamic": {"train": 8, "val": 1},
        "static": {"train": 8, "val": 1}
    },
    "down_sample_ratio": {
        "dynamic": {"train": 1, "val": 1},
        "static": {"train": 1, "val": 1}
    },
    "use_streaming": {
        "dynamic": False,
        "static": False
    }
}
```

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

### 1. é«˜å¯æ‰©å±•æ€§
- **å¤šèŠ‚ç‚¹æ”¯æŒ**: æ”¯æŒå¤§è§„æ¨¡å¤šèŠ‚ç‚¹è®­ç»ƒ
- **çµæ´»é…ç½®**: ä¸°å¯Œçš„é…ç½®é€‰é¡¹
- **è‡ªåŠ¨æ‰©å±•**: è‡ªåŠ¨é€‚åº”ä¸åŒè§„æ¨¡çš„é›†ç¾¤
- **èµ„æºä¼˜åŒ–**: æ™ºèƒ½çš„èµ„æºåˆ†é…å’Œä¼˜åŒ–

### 2. é«˜æ€§èƒ½
- **æ•°æ®å¹¶è¡Œ**: é«˜æ•ˆçš„æ•°æ®å¹¶è¡Œç­–ç•¥
- **æ¢¯åº¦åŒæ­¥**: ä¼˜åŒ–çš„æ¢¯åº¦åŒæ­¥æœºåˆ¶
- **å†…å­˜ç®¡ç†**: æ™ºèƒ½çš„GPUå†…å­˜ç®¡ç†
- **æµæ°´çº¿ä¼˜åŒ–**: æ•°æ®åŠ è½½å’Œè®¡ç®—æµæ°´çº¿ä¼˜åŒ–

### 3. æ˜“ç”¨æ€§
- **ç®€å•é…ç½®**: ç®€å•çš„é…ç½®æ¥å£
- **è‡ªåŠ¨æ£€æµ‹**: è‡ªåŠ¨ç¯å¢ƒæ£€æµ‹å’Œé…ç½®
- **ç»Ÿä¸€æ¥å£**: ç»Ÿä¸€çš„è®­ç»ƒå’Œæ¨ç†æ¥å£
- **ä¸°å¯Œæ–‡æ¡£**: å®Œå–„çš„æ–‡æ¡£å’Œç¤ºä¾‹

### 4. ç¨³å®šæ€§
- **å®¹é”™æœºåˆ¶**: å®Œå–„çš„å®¹é”™å’Œæ¢å¤æœºåˆ¶
- **ç›‘æ§å‘Šè­¦**: å®æ—¶çš„ç›‘æ§å’Œå‘Šè­¦
- **æ—¥å¿—ç®¡ç†**: ç»Ÿä¸€çš„æ—¥å¿—ç®¡ç†
- **è°ƒè¯•æ”¯æŒ**: ä¸°å¯Œçš„è°ƒè¯•å·¥å…·

## ğŸ“ æœ€ä½³å®è·µ

### 1. åˆ†å¸ƒå¼è®­ç»ƒé…ç½®
```python
# æ¨èçš„åˆ†å¸ƒå¼é…ç½®
runner_cfg = {
    "accelerator": "gpu",
    "strategy": "ddp",  # åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ
    "devices": 4,        # GPUæ•°é‡
    "num_nodes": 2,       # èŠ‚ç‚¹æ•°é‡
    "precision": "16",    # æ··åˆç²¾åº¦è®­ç»ƒ
    "sync_batchnorm": True,  # åŒæ­¥æ‰¹å½’ä¸€åŒ–
    "gradient_clip_val": 1.0,  # æ¢¯åº¦è£å‰ª
}
```

### 2. æ•°æ®é‡‡æ ·å™¨ä¼˜åŒ–
```python
# ä¼˜åŒ–çš„é‡‡æ ·å™¨é…ç½®
sampler_cfg = {
    "type": "RankSplitSampler",
    "shuffle": True,
    "down_sample_ratio": 1,
    "use_streaming": False,  # å¤§æ•°æ®é›†æ—¶å¯ç”¨
    "batch_size": 8,
    "seed": 42,  # å›ºå®šç§å­ç¡®ä¿å¯é‡ç°æ€§
}
```

### 3. æ€§èƒ½è°ƒä¼˜å»ºè®®
```python
# æ€§èƒ½ä¼˜åŒ–é…ç½®
optimization_cfg = {
    "accumulate_grad_batches": 2,  # æ¢¯åº¦ç´¯ç§¯
    "precision": "16",             # æ··åˆç²¾åº¦
    "num_workers": 4,              # æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹
    "pin_memory": True,            # å†…å­˜å›ºå®š
    "persistent_workers": True,      # æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹
}
```

## ğŸ‰ æ€»ç»“

LeapAIæ¡†æ¶çš„åˆ†å¸ƒå¼è®­ç»ƒå’Œéƒ¨ç½²æœºåˆ¶æä¾›äº†å®Œæ•´çš„å¤§è§„æ¨¡è®­ç»ƒè§£å†³æ–¹æ¡ˆï¼š

### âœ… æ ¸å¿ƒåŠŸèƒ½
1. **åˆ†å¸ƒå¼ç¯å¢ƒç®¡ç†**: å®Œå–„çš„åˆ†å¸ƒå¼ç¯å¢ƒæ£€æµ‹å’Œç®¡ç†
2. **æ•°æ®å¹¶è¡Œç­–ç•¥**: é«˜æ•ˆçš„æ•°æ®å¹¶è¡Œå’Œé‡‡æ ·ç­–ç•¥
3. **å¤šä»»åŠ¡åè°ƒ**: æ™ºèƒ½çš„å¤šä»»åŠ¡è®­ç»ƒåè°ƒæœºåˆ¶
4. **èµ„æºç®¡ç†**: ä¼˜åŒ–çš„GPUå’Œå†…å­˜èµ„æºç®¡ç†
5. **å®¹é”™æ¢å¤**: å®Œå–„çš„å®¹é”™å’Œæ¢å¤æœºåˆ¶

### ğŸ”§ è®¾è®¡ä¼˜åŠ¿
1. **é«˜å¯æ‰©å±•æ€§**: æ”¯æŒå¤§è§„æ¨¡å¤šèŠ‚ç‚¹è®­ç»ƒ
2. **é«˜æ€§èƒ½**: ä¼˜åŒ–çš„å¹¶è¡Œç­–ç•¥å’Œèµ„æºåˆ©ç”¨
3. **æ˜“ç”¨æ€§**: ç®€å•çš„é…ç½®å’Œç»Ÿä¸€çš„æ¥å£
4. **ç¨³å®šæ€§**: å®Œå–„çš„å®¹é”™å’Œç›‘æ§æœºåˆ¶
5. **çµæ´»æ€§**: ä¸°å¯Œçš„é…ç½®é€‰é¡¹å’Œæ‰©å±•èƒ½åŠ›

### ğŸ“š å­¦ä¹ ä»·å€¼
é€šè¿‡æ·±å…¥ç†è§£LeapAIçš„åˆ†å¸ƒå¼æœºåˆ¶ï¼Œå¯ä»¥æŒæ¡ï¼š
- å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒçš„è®¾è®¡åŸç†
- æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹å¹¶è¡Œçš„å®ç°æ–¹æ³•
- å¤šä»»åŠ¡åˆ†å¸ƒå¼è®­ç»ƒçš„åè°ƒç­–ç•¥
- åˆ†å¸ƒå¼ç³»ç»Ÿçš„å®¹é”™å’Œæ¢å¤æœºåˆ¶
- é«˜æ€§èƒ½è®¡ç®—ç³»ç»Ÿçš„ä¼˜åŒ–æŠ€å·§

è¿™ä¸ªåˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿä¸ºLeapAIæ¡†æ¶çš„å¤§è§„æ¨¡åº”ç”¨æä¾›äº†å¼ºå¤§çš„åŸºç¡€æ”¯æ’‘ã€‚

## ğŸ“š ç›¸å…³èµ„æº

- **[`leapai/distributed.py`](../leapai/distributed.py)** - åˆ†å¸ƒå¼å·¥å…·å‡½æ•°
- **[`leapai/data/sampler/rank_split_sampler.py`](../leapai/data/sampler/rank_split_sampler.py)** - åˆ†å¸ƒå¼é‡‡æ ·å™¨
- **[`tools/main.py`](../tools/main.py)** - ä¸»å…¥å£ç¨‹åº
- **[`projects/perception/entry.py`](../projects/perception/entry.py)** - æ„ŸçŸ¥é¡¹ç›®é…ç½®
- **[`leapai/data/dataloader/combined_dataloader.py`](../leapai/data/dataloader/combined_dataloader.py)** - ç»„åˆæ•°æ®åŠ è½½å™¨

é€šè¿‡è¿™äº›è¯¦ç»†çš„å­¦ä¹ èµ„æºï¼Œæ‚¨å¯ä»¥å…¨é¢æŒæ¡LeapAIæ¡†æ¶çš„åˆ†å¸ƒå¼è®­ç»ƒæœºåˆ¶ï¼Œä¸ºå¤§è§„æ¨¡æ·±åº¦å­¦ä¹ åº”ç”¨å¥ å®šåšå®åŸºç¡€ã€‚

#### 5.2 ä¸»å‡½æ•°æµç¨‹ (ç¬¬37-92è¡Œ)

##### ç¯å¢ƒåˆå§‹åŒ–
```python
def main(args):
    """Entrance function."""
    seed_everything(args.seed)
    cfg_path = args.config
    cfg = Config.fromfile(cfg_path)
    reset_gpu()  # é‡ç½® GPU çŠ¶æ€
```

**åˆå§‹åŒ–æ­¥éª¤**:
1. **ç§å­è®¾ç½®**: è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
2. **é…ç½®åŠ è½½**: åŠ è½½é…ç½®æ–‡ä»¶
3. **GPUé‡ç½®**: é‡ç½®GPUçŠ¶æ€

##### ç¯å¢ƒä¿¡æ¯æ”¶é›†
```python
env_info_dict = collect_env()
env_info = "\n".join([(f"{k}: {v}") for k, v in env_info_dict.items()])
dash_line = "-" * 79 + "\n"
rank_zero_info(
    "Environment info:\n" + dash_line + env_info + "\n" + dash_line
)
```

**ä¿¡æ¯è¾“å‡º**:
- **ç¯å¢ƒè¯¦æƒ…**: è¾“å‡ºå®Œæ•´çš„è¿è¡Œç¯å¢ƒä¿¡æ¯
- **ä¸»è¿›ç¨‹é™åˆ¶**: åªåœ¨ä¸»è¿›ç¨‹è¾“å‡ºä¿¡æ¯
- **æ ¼å¼åŒ–è¾“å‡º**: ä½¿ç”¨åˆ†éš”çº¿ç¾åŒ–è¾“å‡º

##### è®­ç»ƒå™¨æ„å»ºå’Œæ‰§è¡Œ
```python
with RegistryContext():
    runner = build_from_registry(runner_cfg)  # æ„å»ºè®­ç»ƒå™¨
    model = build_from_registry(cfg.graph_model) # æ„å»ºæ¨¡å‹
    data_module = build_from_registry(cfg.data_module)  # æ„å»ºæ•°æ®æ¨¡å—
    
    if state == "train":
        runner.fit(model=model, datamodule=data_module, ckpt_path=resume_ckpt)
    elif state == "val":
        runner.validate(model, data_module)
    elif state == "test":
        runner.test(model, data_module)
    elif state == "predict":
        runner.predict(model, data_module)
```

**æ‰§è¡Œæµç¨‹**:
1. **æ³¨å†Œä¸Šä¸‹æ–‡**: åœ¨æ³¨å†Œè¡¨ä¸Šä¸‹æ–‡ä¸­æ„å»ºç»„ä»¶
2. **ç»„ä»¶æ„å»º**: æ„å»ºè®­ç»ƒå™¨ã€æ¨¡å‹å’Œæ•°æ®æ¨¡å—
3. **çŠ¶æ€æ‰§è¡Œ**: æ ¹æ®çŠ¶æ€æ‰§è¡Œç›¸åº”æ“ä½œ

### 6. æ„ŸçŸ¥é¡¹ç›®åˆ†å¸ƒå¼é…ç½® - [`projects/perception/entry.py`](../projects/perception/entry.py)

#### 6.1 åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ (ç¬¬46è¡Œ)
```python
num_machines = int(os.environ.get("NNODES", 1))
```

**ç¯å¢ƒå˜é‡**:
- **NNODES**: èŠ‚ç‚¹æ•°é‡ï¼Œé»˜è®¤ä¸º1
- **è‡ªåŠ¨æ£€æµ‹**: ä»ç¯å¢ƒå˜é‡è·å–åˆ†å¸ƒå¼é…ç½®

#### 6.2 åˆ†å¸ƒå¼æ•°æ®é‡‡æ ·é…ç½® (ç¬¬133-156è¡Œ)
```python
train_sampler = dict(
    type="RankSplitSampler",
    shuffle=True,
    down_sample_ratio=MAIN_CFG.down_sample_ratio[task_name]["train"],
    use_streaming=MAIN_CFG.use_streaming[task_name],
    batch_size=MAIN_CFG.batch_sizes[task_name]["train"],
)
```

**é‡‡æ ·å™¨é…ç½®**:
- **ç±»å‹æŒ‡å®š**: ä½¿ç”¨RankSplitSampler
- **ä¸‹é‡‡æ ·**: æ”¯æŒæ•°æ®ä¸‹é‡‡æ ·
- **æµå¼å¤„ç†**: æ”¯æŒæµå¼æ•°æ®åŠ è½½
- **æ‰¹æ¬¡å¤§å°**: æŒ‡å®šæ‰¹æ¬¡å¤§å°

#### 6.3 åˆ†å¸ƒå¼è®­ç»ƒå™¨é…ç½® (ç¬¬567-608è¡Œ)
```python
runner = dict(
    type=L.Trainer,
    accelerator=base.accelerator,
    strategy=base.strategy,
    devices=devices_id,
    num_nodes=num_machines,
    precision=precision,
    use_distributed_sampler=use_distributed_sampler,
    sync_batchnorm=False,
)
```

**è®­ç»ƒå™¨é…ç½®**:
- **åŠ é€Ÿå™¨**: GPU/CPUåŠ é€Ÿå™¨é…ç½®
- **ç­–ç•¥**: åˆ†å¸ƒå¼ç­–ç•¥
- **è®¾å¤‡**: æŒ‡å®šGPUè®¾å¤‡
- **èŠ‚ç‚¹æ•°**: åˆ†å¸ƒå¼èŠ‚ç‚¹æ•°é‡
- **ç²¾åº¦**: æ··åˆç²¾åº¦è®­ç»ƒ
- **åˆ†å¸ƒå¼é‡‡æ ·å™¨**: è‡ªåŠ¨è½¬æ¢é‡‡æ ·å™¨

## ğŸ¯ åˆ†å¸ƒå¼è®­ç»ƒæ¶æ„

### 1. æ•´ä½“æ¶æ„å›¾

```mermaid
graph TD
    A[ä¸»è¿›ç¨‹] --> B[åˆ†å¸ƒå¼åˆå§‹åŒ–]
    B --> C[ç¯å¢ƒæ£€æµ‹]
    C --> D[GPUåˆ†é…]
    D --> E[æ•°æ®åˆ†ç‰‡]
    E --> F[æ¨¡å‹åŒæ­¥]
    F --> G[è®­ç»ƒå¾ªç¯]
    G --> H[æ¢¯åº¦åŒæ­¥]
    H --> I[å‚æ•°æ›´æ–°]
    I --> G
    
    J[å­è¿›ç¨‹1] --> K[GPU0]
    L[å­è¿›ç¨‹2] --> M[GPU1]
    N[å­è¿›ç¨‹N] --> O[GPUN]
    
    B --> J
    B --> L
    B --> N
```

### 2. æ•°æ®å¹¶è¡Œç­–ç•¥

#### 2.1 æ•°æ®åˆ†ç‰‡
```python
# RankSplitSamplerå®ç°æ•°æ®åˆ†ç‰‡
def get_epoch_indices(self):
    # æ¯ä¸ªrankè·å–ä¸åŒçš„æ•°æ®å­é›†
    final_indices = []
    # æ ¹æ®rankå’Œworld_sizeåˆ†é…æ•°æ®
    # ç¡®ä¿æ¯ä¸ªè¿›ç¨‹å¤„ç†ä¸åŒçš„æ•°æ®
```

#### 2.2 æ¢¯åº¦åŒæ­¥
```python
# NodeGraphä¸­çš„æ¢¯åº¦åŒæ­¥
def training_step(self, batches, batch_idx):
    need_sync = self._is_grad_sync_step()
    
    for task_id, (task_name, batch) in enumerate(batches.items()):
        final_task = self._is_final_task(task_id)
        sync_context = self.trainer.model.no_sync
        if need_sync and final_task:
            sync_context = nullcontext
        
        with sync_context():
            # è®¡ç®—æ¢¯åº¦
            self.manual_backward(total_loss)
    
    if need_sync:
        opt.step()  # åŒæ­¥æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°
```

### 3. å¤šä»»åŠ¡åˆ†å¸ƒå¼åè°ƒ

#### 3.1 ä»»åŠ¡æ•°æ®åˆ†é…
```python
# æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹çš„æ•°æ®åŠ è½½å™¨
task_train_dataloaders = {}
for task_name in MAIN_CFG.multi_task_config.keys():
    train_dataloader = dict(
        dataset=train_dataset,
        sampler=train_sampler,  # åˆ†å¸ƒå¼é‡‡æ ·å™¨
        batch_size=MAIN_CFG.batch_sizes[task_name]["train"],
    )
    task_train_dataloaders[task_name] = train_dataloader

# ç»„åˆæ•°æ®åŠ è½½å™¨
train_dataloaders = dict(
    type=CombinedLoader,
    iterables=task_train_dataloaders,
    mode="max_size_cycle",
)
```

#### 3.2 å¤šä»»åŠ¡æ¢¯åº¦åè°ƒ
```python
# NodeGraphä¸­çš„å¤šä»»åŠ¡å¤„ç†
for task_id, (task_name, batch) in enumerate(batches.items()):
    # è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„æŸå¤±
    losses = topo_fn("train", self, batch, batch_idx)
    total_loss = sum(flat_losses.values())
    total_loss = total_loss * self.task_loss_weights[task_name]
    
    # ç´¯ç§¯æ¢¯åº¦
    self.manual_backward(total_loss)

# åœ¨æœ€åä¸€ä¸ªä»»åŠ¡ååŒæ­¥æ¢¯åº¦
if need_sync:
    opt.step()
    opt.zero_grad(set_to_none=True)
```

## ğŸš€ éƒ¨ç½²æœºåˆ¶

### 1. å•æœºå¤šå¡éƒ¨ç½²

#### 1.1 å¯åŠ¨å‘½ä»¤
```bash
# ä½¿ç”¨torch.distributed.launch
python -m torch.distributed.launch \
    --nproc_per_node=8 \
    --master_port=29500 \
    tools/main.py \
    --config projects/perception/configs/lpperception_current.py \
    --state train
```

#### 1.2 ç¯å¢ƒå˜é‡è®¾ç½®
```bash
export LOCAL_RANK=0  # æ¯ä¸ªè¿›ç¨‹çš„æœ¬åœ°ç§©
export WORLD_SIZE=8   # æ€»è¿›ç¨‹æ•°
export MASTER_ADDR=localhost  # ä¸»èŠ‚ç‚¹åœ°å€
export MASTER_PORT=29500      # ä¸»èŠ‚ç‚¹ç«¯å£
```

### 2. å¤šæœºå¤šå¡éƒ¨ç½²

#### 2.1 ä¸»èŠ‚ç‚¹å¯åŠ¨
```bash
python -m torch.distributed.launch \
    --nproc_per_node=8 \
    --nnodes=2 \
    --node_rank=0 \
    --master_addr="192.168.1.100" \
    --master_port=29500 \
    tools/main.py \
    --config config.py \
    --state train
```

#### 2.2 ä»èŠ‚ç‚¹å¯åŠ¨
```bash
python -m torch.distributed.launch \
    --nproc_per_node=8 \
    --nnodes=2 \
    --node_rank=1 \
    --master_addr="192.168.1.100" \
    --master_port=29500 \
    tools/main.py \
    --config config.py \
    --state train
```

### 3. å®¹å™¨åŒ–éƒ¨ç½²

#### 3.1 Dockeré…ç½®
```dockerfile
FROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY . /workspace
WORKDIR /workspace

# åˆ†å¸ƒå¼è®­ç»ƒå…¥å£
CMD ["python", "-m", "torch.distributed.launch", "--nproc_per_node=8", "tools/main.py"]
```

#### 3.2 Kuberneteséƒ¨ç½²
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: leapai-training
