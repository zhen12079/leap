#!/usr/bin/env python3
"""
LeapAIæ¡†æ¶å­¦ä¹  - é˜¶æ®µ4ï¼šæ¨¡å‹æ„å»ºå’ŒNodeGraphæœºåˆ¶å®è·µ

æœ¬é˜¶æ®µå­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£NodeGraphè®¾è®¡ç†å¿µå’Œæ¶æ„
2. å­¦ä¹ èŠ‚ç‚¹åŒ–æ¨¡å‹æ„å»ºæ–¹æ³•
3. æŒæ¡æ¨¡å‹æ‹“æ‰‘å®šä¹‰å’Œè¿æ¥
4. å®è·µè‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘
"""

import os
import sys
import torch
import torch.nn as nn
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def explore_node_graph_architecture():
    """æ¢ç´¢NodeGraphæ¶æ„"""
    
    print("=" * 60)
    print("ğŸ—ï¸ NodeGraphæ¶æ„æ¢ç´¢")
    print("=" * 60)
    
    try:
        # è¯»å–NodeGraphæ ¸å¿ƒæ–‡ä»¶
        node_graph_path = "leapai/model/node_graph.py"
        
        if not os.path.exists(node_graph_path):
            print(f"âŒ NodeGraphæ–‡ä»¶ä¸å­˜åœ¨: {node_graph_path}")
            return False
        
        with open(node_graph_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print("âœ… NodeGraphæ ¸å¿ƒæ–‡ä»¶è¯»å–æˆåŠŸ")
        
        # åˆ†æå…³é”®ç±»å’Œæ–¹æ³•
        key_classes = []
        key_methods = []
        
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('class '):
                class_name = line.split('(')[0].replace('class ', '').strip(':')
                key_classes.append(class_name)
            elif 'def ' in line and not line.startswith('#'):
                method_name = line.split('(')[0].strip().replace('def ', '')
                if not method_name.startswith('_'):
                    key_methods.append(method_name)
        
        print(f"\nğŸ“‹ å‘ç°çš„å…³é”®ç±»:")
        for i, cls in enumerate(key_classes, 1):
            print(f"  {i}. {cls}")
        
        print(f"\nğŸ“‹ å‘ç°çš„å…¬å…±æ–¹æ³•:")
        for i, method in enumerate(key_methods[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  {i}. {method}")
        
        return True
        
    except Exception as e:
        print(f"âŒ NodeGraphæ¶æ„æ¢ç´¢å¤±è´¥: {e}")
        return False

def understand_node_concept():
    """ç†è§£èŠ‚ç‚¹æ¦‚å¿µ"""
    
    print("\n" + "=" * 60)
    print("ğŸ”— èŠ‚ç‚¹æ¦‚å¿µç†è§£")
    print("=" * 60)
    
    try:
        # å°è¯•å¯¼å…¥NodeGraphç›¸å…³æ¨¡å—
        from leapai.model.node_graph import NodeGraph, Node
        
        print("âœ… NodeGraphæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ†æNodeåŸºç±»
        if hasattr(Node, '__doc__') and Node.__doc__:
            print(f"\nğŸ“– Nodeç±»æ–‡æ¡£:")
            print(Node.__doc__[:200] + "..." if len(Node.__doc__) > 200 else Node.__doc__)
        
        # æŸ¥çœ‹Nodeçš„æ–¹æ³•
        node_methods = [method for method in dir(Node) if not method.startswith('_')]
        print(f"\nğŸ”§ Nodeç±»æ–¹æ³•:")
        for i, method in enumerate(node_methods, 1):
            print(f"  {i}. {method}")
        
        # æŸ¥çœ‹NodeGraphçš„æ–¹æ³•
        graph_methods = [method for method in dir(NodeGraph) if not method.startswith('_')]
        print(f"\nğŸ”§ NodeGraphç±»æ–¹æ³•:")
        for i, method in enumerate(graph_methods[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  {i}. {method}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("ğŸ’¡ å¯èƒ½éœ€è¦å…ˆå®Œæˆç¯å¢ƒé…ç½®")
        return False
    except Exception as e:
        print(f"âŒ èŠ‚ç‚¹æ¦‚å¿µç†è§£å¤±è´¥: {e}")
        return False

def analyze_model_topology():
    """åˆ†ææ¨¡å‹æ‹“æ‰‘ç»“æ„"""
    
    print("\n" + "=" * 60)
    print("ğŸŒ æ¨¡å‹æ‹“æ‰‘ç»“æ„åˆ†æ")
    print("=" * 60)
    
    try:
        # æŸ¥çœ‹perceptioné¡¹ç›®çš„æ¨¡å‹é…ç½®
        model_configs = []
        perception_model_dir = "projects/perception/model"
        
        if os.path.exists(perception_model_dir):
            for root, dirs, files in os.walk(perception_model_dir):
                for file in files:
                    if file.endswith('.py') and not file.startswith('__'):
                        rel_path = os.path.relpath(os.path.join(root, file), perception_model_dir)
                        model_configs.append(rel_path)
        
        print(f"ğŸ“ å‘ç°çš„æ¨¡å‹æ–‡ä»¶ ({len(model_configs)}ä¸ª):")
        for i, config in enumerate(model_configs[:15], 1):  # åªæ˜¾ç¤ºå‰15ä¸ª
            print(f"  {i:2d}. {config}")
        
        if len(model_configs) > 15:
            print(f"     ... è¿˜æœ‰ {len(model_configs) - 15} ä¸ªæ–‡ä»¶")
        
        # åˆ†æå…³é”®æ¨¡å‹ç»„ä»¶
        key_components = [
            "backbone", "neck", "head", "fusion", "task_module"
        ]
        
        print(f"\nğŸ—ï¸ å…³é”®æ¨¡å‹ç»„ä»¶:")
        for component in key_components:
            component_dir = f"projects/perception/model/{component}"
            if os.path.exists(component_dir):
                files = [f for f in os.listdir(component_dir) if f.endswith('.py')]
                print(f"  â€¢ {component}: {len(files)} ä¸ªæ–‡ä»¶")
                for file in files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"    - {file}")
                if len(files) > 3:
                    print(f"    - ... è¿˜æœ‰ {len(files) - 3} ä¸ªæ–‡ä»¶")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ‹“æ‰‘åˆ†æå¤±è´¥: {e}")
        return False

def practice_node_creation():
    """å®è·µèŠ‚ç‚¹åˆ›å»º"""
    
    print("\n" + "=" * 60)
    print("ğŸ› ï¸ èŠ‚ç‚¹åˆ›å»ºå®è·µ")
    print("=" * 60)
    
    try:
        # å°è¯•å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from leapai.model.node_graph import Node, NodeGraph
        from leapai.registry import RegistryContext, build_from_registry
        
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„è‡ªå®šä¹‰èŠ‚ç‚¹ç¤ºä¾‹
        class SimpleConvNode(Node):
            """ç®€å•çš„å·ç§¯èŠ‚ç‚¹ç¤ºä¾‹"""
            
            def __init__(self, in_channels, out_channels, kernel_size=3):
                super().__init__()
                self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
                self.bn = nn.BatchNorm2d(out_channels)
                self.relu = nn.ReLU(inplace=True)
            
            def forward(self, x):
                return self.relu(self.bn(self.conv(x)))
        
        class SimplePoolingNode(Node):
            """ç®€å•çš„æ± åŒ–èŠ‚ç‚¹ç¤ºä¾‹"""
            
            def __init__(self, pool_type='max', kernel_size=2):
                super().__init__()
                if pool_type == 'max':
                    self.pool = nn.MaxPool2d(kernel_size)
                else:
                    self.pool = nn.AvgPool2d(kernel_size)
            
            def forward(self, x):
                return self.pool(x)
        
        print("âœ… è‡ªå®šä¹‰èŠ‚ç‚¹ç±»åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•èŠ‚ç‚¹åŠŸèƒ½
        with torch.no_grad():
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_input = torch.randn(1, 64, 32, 32)
            
            # åˆ›å»ºå¹¶æµ‹è¯•å·ç§¯èŠ‚ç‚¹
            conv_node = SimpleConvNode(64, 128)
            conv_output = conv_node(test_input)
            print(f"âœ… å·ç§¯èŠ‚ç‚¹æµ‹è¯•æˆåŠŸ: {test_input.shape} -> {conv_output.shape}")
            
            # åˆ›å»ºå¹¶æµ‹è¯•æ± åŒ–èŠ‚ç‚¹
            pool_node = SimplePoolingNode('max', 2)
            pool_output = pool_node(conv_output)
            print(f"âœ… æ± åŒ–èŠ‚ç‚¹æµ‹è¯•æˆåŠŸ: {conv_output.shape} -> {pool_output.shape}")
        
        print("âœ… èŠ‚ç‚¹åˆ›å»ºå®è·µå®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ èŠ‚ç‚¹åˆ›å»ºå®è·µå¤±è´¥: {e}")
        return False

def analyze_existing_models():
    """åˆ†æç°æœ‰æ¨¡å‹å®ç°"""
    
    print("\n" + "=" * 60)
    print("ğŸ” ç°æœ‰æ¨¡å‹å®ç°åˆ†æ")
    print("=" * 60)
    
    try:
        # åˆ†æperceptioné¡¹ç›®çš„æ¨¡å‹åŸºç±»
        model_base_path = "projects/perception/model_base.py"
        
        if os.path.exists(model_base_path):
            with open(model_base_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print("âœ… æ¨¡å‹åŸºç±»æ–‡ä»¶è¯»å–æˆåŠŸ")
            
            # æå–å…³é”®ç±»å’Œæ–¹æ³•
            lines = content.split('\n')
            classes = []
            methods = []
            
            for line in lines:
                line = line.strip()
                if line.startswith('class '):
                    class_name = line.split('(')[0].replace('class ', '').strip(':')
                    classes.append(class_name)
                elif line.startswith('    def ') and not line.startswith('    def _'):
                    method_name = line.split('(')[0].strip().replace('def ', '')
                    methods.append(method_name)
            
            print(f"\nğŸ“‹ å‘ç°çš„æ¨¡å‹ç±»:")
            for i, cls in enumerate(classes, 1):
                print(f"  {i}. {cls}")
            
            print(f"\nğŸ“‹ å‘ç°çš„å…¬å…±æ–¹æ³•:")
            for i, method in enumerate(methods[:8], 1):
                print(f"  {i}. {method}")
        
        # åˆ†æå…·ä½“çš„æ¨¡å‹å¤´å®ç°
        head_dir = "projects/perception/model/head"
        if os.path.exists(head_dir):
            head_files = [f for f in os.listdir(head_dir) if f.endswith('.py')]
            print(f"\nğŸ¯ æ¨¡å‹å¤´å®ç° ({len(head_files)}ä¸ª):")
            for i, file in enumerate(head_files, 1):
                print(f"  {i}. {file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç°æœ‰æ¨¡å‹åˆ†æå¤±è´¥: {e}")
        return False

def practice_model_configuration():
    """å®è·µæ¨¡å‹é…ç½®"""
    
    print("\n" + "=" * 60)
    print("âš™ï¸ æ¨¡å‹é…ç½®å®è·µ")
    print("=" * 60)
    
    try:
        # åˆ†æé…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹å®šä¹‰
        config_path = "projects/perception/configs/lpperception_current_hpa_step1.py"
        
        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        # è¯»å–é…ç½®æ–‡ä»¶
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print("âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ")
        
        # æŸ¥æ‰¾æ¨¡å‹ç›¸å…³é…ç½®
        model_sections = []
        lines = content.split('\n')
        current_section = []
        in_model_section = False
        
        for line in lines:
            if any(keyword in line for keyword in ['graph_model', 'model', 'backbone', 'neck', 'head']):
                in_model_section = True
                current_section = [line]
            elif in_model_section:
                if line.strip() == '' or (line.startswith(' ') == False and not line.startswith('\t')):
                    if current_section:
                        model_sections.append('\n'.join(current_section))
                        current_section = []
                    in_model_section = False
                else:
                    current_section.append(line)
        
        if current_section:
            model_sections.append('\n'.join(current_section))
        
        print(f"\nğŸ“‹ å‘ç°çš„æ¨¡å‹é…ç½®æ®µ ({len(model_sections)}ä¸ª):")
        for i, section in enumerate(model_sections, 1):
            lines = section.split('\n')
            title = lines[0].strip() if lines else "Unknown"
            print(f"  {i}. {title}")
            # æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
            for line in lines[1:4]:
                if line.strip():
                    print(f"     {line.strip()}")
            print()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹é…ç½®å®è·µå¤±è´¥: {e}")
        return False

def show_learning_summary():
    """æ˜¾ç¤ºå­¦ä¹ æ€»ç»“"""
    
    print("\n" + "=" * 60)
    print("ğŸ“š é˜¶æ®µ4å­¦ä¹ æ€»ç»“")
    print("=" * 60)
    
    summary_points = [
        "ğŸ—ï¸ NodeGraphæ¶æ„ï¼šç†è§£äº†èŠ‚ç‚¹åŒ–æ¨¡å‹çš„è®¾è®¡ç†å¿µ",
        "ğŸ”— èŠ‚ç‚¹æ¦‚å¿µï¼šæŒæ¡äº†NodeåŸºç±»å’ŒèŠ‚ç‚¹è¿æ¥æœºåˆ¶",
        "ğŸŒ æ¨¡å‹æ‹“æ‰‘ï¼šåˆ†æäº†æ¨¡å‹çš„å±‚æ¬¡ç»“æ„å’Œç»„ä»¶å…³ç³»",
        "ğŸ› ï¸ èŠ‚ç‚¹åˆ›å»ºï¼šå®è·µäº†è‡ªå®šä¹‰èŠ‚ç‚¹çš„å¼€å‘",
        "ğŸ” æ¨¡å‹åˆ†æï¼šæ·±å…¥äº†è§£äº†ç°æœ‰æ¨¡å‹çš„å®ç°æ–¹å¼",
        "âš™ï¸ é…ç½®ç³»ç»Ÿï¼šæŒæ¡äº†æ¨¡å‹é…ç½®çš„å®šä¹‰å’Œä½¿ç”¨"
    ]
    
    for point in summary_points:
        print(f"  {point}")
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®:")
    next_steps = [
        "1. æ·±å…¥ç†è§£å¤šä»»åŠ¡è®­ç»ƒæœºåˆ¶",
        "2. å­¦ä¹ æ„ŸçŸ¥ä»»åŠ¡çš„å…·ä½“å®ç°",
        "3. æŒæ¡åˆ†å¸ƒå¼è®­ç»ƒå’Œéƒ¨ç½²",
        "4. å®è·µå®Œæ•´çš„è®­ç»ƒæµç¨‹"
    ]
    
    for step in next_steps:
        print(f"  {step}")
    
    print("\nğŸ’¡ å…³é”®æ–‡ä»¶å›é¡¾:")
    key_files = [
        "â€¢ leapai/model/node_graph.py - NodeGraphæ ¸å¿ƒå®ç°",
        "â€¢ projects/perception/model_base.py - æ¨¡å‹åŸºç±»",
        "â€¢ projects/perception/model/ - å…·ä½“æ¨¡å‹å®ç°",
        "â€¢ projects/perception/configs/ - æ¨¡å‹é…ç½®æ–‡ä»¶"
    ]
    
    for file in key_files:
        print(f"  {file}")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ“ LeapAIæ¡†æ¶å­¦ä¹  - é˜¶æ®µ4ï¼šæ¨¡å‹æ„å»ºå’ŒNodeGraphæœºåˆ¶")
    print("æœ¬é˜¶æ®µå°†æ·±å…¥ç†è§£LeapAIçš„èŠ‚ç‚¹åŒ–æ¨¡å‹æ¶æ„")
    
    try:
        # æ‰§è¡Œå­¦ä¹ æ­¥éª¤
        steps = [
            ("æ¢ç´¢NodeGraphæ¶æ„", explore_node_graph_architecture),
            ("ç†è§£èŠ‚ç‚¹æ¦‚å¿µ", understand_node_concept),
            ("åˆ†ææ¨¡å‹æ‹“æ‰‘ç»“æ„", analyze_model_topology),
            ("å®è·µèŠ‚ç‚¹åˆ›å»º", practice_node_creation),
            ("åˆ†æç°æœ‰æ¨¡å‹å®ç°", analyze_existing_models),
            ("å®è·µæ¨¡å‹é…ç½®", practice_model_configuration)
        ]
        
        completed_steps = 0
        for step_name, step_func in steps:
            print(f"\nğŸ”„ æ‰§è¡Œæ­¥éª¤: {step_name}")
            if step_func():
                completed_steps += 1
                print(f"âœ… {step_name} å®Œæˆ")
            else:
                print(f"âŒ {step_name} å¤±è´¥")
        
        # æ˜¾ç¤ºå­¦ä¹ æ€»ç»“
        show_learning_summary()
        
        print(f"\nğŸ‰ é˜¶æ®µ4å­¦ä¹ å®Œæˆï¼")
        print(f"å®Œæˆæ­¥éª¤: {completed_steps}/{len(steps)}")
        
        return completed_steps == len(steps)
        
    except Exception as e:
        print(f"âŒ å­¦ä¹ è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
